{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 150,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data minuplations modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#import viuslaization models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import normalization modules\n",
<<<<<<< HEAD
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
=======
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "#import preprocessing train_test_split module\n",
    "# from sklearn.model_selection import train_test_split # Do not need this with the multiple datasets kaggle has given\n",
    "\n",
    "#import machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#import NN models - Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#import NN models - Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#import accuracy_score function from sklearn.metrics to score models better\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 151,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into dataframes\n",
    "#data retrieved from kaggle competitions\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "gender_submission = pd.read_csv(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pclass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Pclass'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [152]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Dummies variables for PClass to prevent bias toward one number being weighed more than another\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train, pd\u001b[38;5;241m.\u001b[39mget_dummies(train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([test, pd\u001b[38;5;241m.\u001b[39mget_dummies(\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Let's make the sex cloumn into a binary column\u001b[39;00m\n\u001b[0;32m      6\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex_binary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mSex\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}) \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Pclass'"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "#Dummies variables for PClass to prevent bias toward one number being weighed more than another\n",
    "train = pd.concat([train, pd.get_dummies(train[\"Pclass\"], prefix='Pclass')], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test[\"Pclass\"], prefix='Pclass')], axis=1)\n",
    "\n",
    "# Let's make the sex cloumn into a binary column\n",
    "train['Sex_binary'] = train.Sex.map({\"male\": 0, \"female\": 1}) \n",
    "test['Sex_binary'] = test.Sex.map({\"male\": 0, \"female\": 1})\n",
    "\n",
<<<<<<< HEAD
    "# train.head()"
=======
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from stories of Titanic that women and children  can be saved in a life raft, but what about men? \n",
    "I think we should address gender and age next as it may help our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could of done this earlier, but in this data, I am not likely to use the following columns right now. I may need them later for further analysis but at present they are just cluttering up my dataset. Lets just drop them for now from each dataframe.\n",
    "\n",
    "Pclass, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
       "0            1         0  22.0      1      0   7.2500         0         0   \n",
       "1            2         1  38.0      1      0  71.2833         1         0   \n",
       "2            3         1  26.0      0      0   7.9250         0         0   \n",
       "3            4         1  35.0      1      0  53.1000         1         0   \n",
       "4            5         0  35.0      0      0   8.0500         0         0   \n",
       "\n",
       "   Pclass_3  Sex_binary  \n",
       "0         1           0  \n",
       "1         0           1  \n",
       "2         1           1  \n",
       "3         0           1  \n",
       "4         1           0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "# columns_to_drop = [\"Pclass\", \"Name\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "columns_to_drop = [\"Pclass\", \"Name\", \"Sex\",  \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "train = train.drop(columns_to_drop, axis = 1)\n",
    "test = test.drop(columns_to_drop, axis = 1)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>29.758889</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.352413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>13.002570</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.477990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838   29.758889    0.523008    0.381594   \n",
       "std     257.353842    0.486592   13.002570    1.102743    0.806057   \n",
       "min       1.000000    0.000000    0.420000    0.000000    0.000000   \n",
       "25%     223.500000    0.000000   22.000000    0.000000    0.000000   \n",
       "50%     446.000000    0.000000   30.000000    0.000000    0.000000   \n",
       "75%     668.500000    1.000000   35.000000    1.000000    0.000000   \n",
       "max     891.000000    1.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Pclass_1    Pclass_2    Pclass_3  Sex_binary  \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
       "mean    32.204208    0.242424    0.206510    0.551066    0.352413  \n",
       "std     49.693429    0.428790    0.405028    0.497665    0.477990  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      7.910400    0.000000    0.000000    0.000000    0.000000  \n",
       "50%     14.454200    0.000000    0.000000    1.000000    0.000000  \n",
       "75%     31.000000    0.000000    0.000000    1.000000    1.000000  \n",
       "max    512.329200    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fill in the ages with the mean of all ages.\n",
    "train['Age'].fillna(value = round(train['Age'].mean()), inplace = True) #look up .fillna function\n",
    "test['Age'].fillna(value = round(test['Age'].mean()), inplace = True) \n",
    "train[\"Age\"].count() #now we have every row accounted for. \n",
    "\n",
    "# test[\"Fare\"].dropna(axis=0, how='any', inplace=True)\n",
    "test['Fare'].fillna(value = round(test['Fare'].mean()), inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    " We were given two datasets so we will split them accordingly. WIth one dataset we would use the train_test_split function from the model selection of sklearn. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": null,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to focus on training a model on Age, Sex_binary, FirstClass, SecondClass, ThirdClass, \"SibSp\", \"Parch\", \"Fare\"\n",
    "#The goal is to predict whether or not the user survived based on this. \n",
    "train_features = train[[\"Age\", \"Sex_binary\", \"Pclass_1\",\"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "train_labels = train[\"Survived\"]\n",
    "test_features = test[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "test_labels = gender_submission[\"Survived\"]\n",
    "\n",
    "#initialize an accuracy test key = model , value = accuracy score\n",
<<<<<<< HEAD
    "model_accuracy_titanic_compare = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, scaler, train_features, train_labels, test_features, test_labels):\n",
    "    train_features_scaled = scaler.fit_transform(train_features)\n",
    "    test_features_scaled = scaler.transform(test_features)\n",
    "    \n",
    "    model.fit(train_features_scaled, train_labels)\n",
    "    y_predict = model.predict(test_features_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, y_predict)\n",
    "    \n",
    "    model_key = f\"{model.__class__.__name__} - {scaler.__class__.__name__}\"\n",
    "    model_accuracy_titanic_compare[model_key] = accuracy\n",
    "    \n",
    "    return accuracy"
=======
    "model_accuracy_titanic_compare = {}\n"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Scalar Models\n",
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
=======
   "execution_count": null,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature data so it has mean = 0 and standard deviation = 1\n",
<<<<<<< HEAD
    "# scaler = StandardScaler()\n",
    "# train_features_Scalar = scaler.fit_transform(train_features)\n",
    "# test_features_Scalar = scaler.transform(test_features)\n",
    "\n",
    "# MinMaxScaler = MinMaxScaler()\n",
    "# train_features_MinMax = scaler.fit_transform(train_features)\n",
    "# test_features_MinMax = scaler.transform(test_features)\n",
    "\n",
    "# robust_scale = RobustScaler()\n",
    "# train_features_Robust = robust_scale.fit_transform(train_features)\n",
    "# test_features_Robust = robust_scale.transform(test_features)"
=======
    "scaler = StandardScaler()\n",
    "train_features_Scalar = scaler.fit_transform(train_features)\n",
    "test_features_Scalar = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxScaler = MinMaxScaler()\n",
    "train_features_MinMax = scaler.fit_transform(train_features)\n",
    "test_features_MinMax = scaler.transform(test_features)"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scale = RobustScaler()\n",
    "train_features_Robust = robust_scale.fit_transform(train_features)\n",
    "test_features_Robust = robust_scale.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all models against 3 scalar functions\n",
    "Not the Neural networks"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 154,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
=======
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
      "text/plain": [
       "{'LogisticRegression - StandardScaler': 0.9641148325358851,\n",
       " 'LogisticRegression - MinMaxScaler': 0.9784688995215312,\n",
       " 'LogisticRegression - RobustScaler': 0.9617224880382775,\n",
       " 'DecisionTreeClassifier - StandardScaler': 0.9617224880382775,\n",
       " 'DecisionTreeClassifier - MinMaxScaler': 0.9617224880382775,\n",
       " 'DecisionTreeClassifier - RobustScaler': 0.9617224880382775,\n",
       " 'RandomForestClassifier - StandardScaler': 0.9330143540669856,\n",
       " 'RandomForestClassifier - MinMaxScaler': 0.9234449760765551,\n",
       " 'RandomForestClassifier - RobustScaler': 0.9210526315789473,\n",
       " 'GaussianNB - StandardScaler': 0.7655502392344498,\n",
       " 'GaussianNB - MinMaxScaler': 0.7655502392344498,\n",
       " 'GaussianNB - RobustScaler': 0.7655502392344498,\n",
       " 'KNeighborsClassifier - StandardScaler': 0.8373205741626795,\n",
       " 'KNeighborsClassifier - MinMaxScaler': 0.8373205741626795,\n",
       " 'KNeighborsClassifier - RobustScaler': 0.8133971291866029,\n",
       " 'SVC - StandardScaler': 0.9665071770334929,\n",
       " 'SVC - MinMaxScaler': 0.9449760765550239,\n",
       " 'SVC - RobustScaler': 0.8325358851674641}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 41,
=======
     "execution_count": 154,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialze Logistic regression Models models\n",
    "model = LogisticRegression()\n",
    "model2 = LogisticRegression()\n",
    "model3 = LogisticRegression()\n",
    "\n",
<<<<<<< HEAD
    "# Initialize DecisionTreeClassifier Models\n",
    "tree_model1 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "tree_model2 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "tree_model3 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# Initilize the RandomForest Classifiers \n",
    "RFC_model1 = RandomForestClassifier(n_estimators=80, criterion='gini', max_depth=4)\n",
    "RFC_model2 = RandomForestClassifier(n_estimators=80, criterion='gini', max_depth=4)\n",
    "RFC_model3 = RandomForestClassifier(n_estimators=80, criterion='gini', max_depth=4)\n",
    "\n",
    "#initialize naive bayes\n",
    "nb_model1 = GaussianNB()\n",
    "nb_model2 = GaussianNB()\n",
    "nb_model3 = GaussianNB()\n",
    "\n",
    "# Initialize KNN\n",
    "knn_model1 = KNeighborsClassifier(n_neighbors=3) \n",
    "knn_model2 = KNeighborsClassifier(n_neighbors=3) \n",
    "knn_model3 = KNeighborsClassifier(n_neighbors=3) \n",
    "\n",
    "# Initilize Support Vector Machines\n",
    "svm_svc_model1 = svm.SVC(kernel='poly', C=1.5) \n",
    "svm_svc_model2 = svm.SVC(kernel='poly', C=1.5) \n",
    "svm_svc_model3 = svm.SVC(kernel='poly', C=1.5) \n",
    "\n",
    "# Train and evaluate models\n",
    "LR_model_acc_score_Scalar = train_and_evaluate_model(model, scaler, train_features, train_labels, test_features, test_labels)\n",
    "LR_model_acc_score_MinMax = train_and_evaluate_model(model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "LR_model_acc_score_Robust = train_and_evaluate_model(model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "DecisionTree_acc_score_Scalar = train_and_evaluate_model(tree_model1, scaler, train_features, train_labels, test_features, test_labels)\n",
    "DecisionTree_acc_score_MinMax = train_and_evaluate_model(tree_model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "DecisionTree_acc_score_Robust = train_and_evaluate_model(tree_model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "RandomForest_acc_score_Scalar = train_and_evaluate_model(RFC_model1, scaler, train_features, train_labels, test_features, test_labels)\n",
    "RandomForest_acc_score_MinMax = train_and_evaluate_model(RFC_model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "RandomForest_acc_score_Robust = train_and_evaluate_model(RFC_model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "NB_acc_score_Scalar = train_and_evaluate_model(nb_model1, scaler, train_features, train_labels, test_features, test_labels)\n",
    "NB_acc_score_MinMax = train_and_evaluate_model(nb_model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "NB_acc_score_Robust = train_and_evaluate_model(nb_model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "KNN_acc_score_Scalar = train_and_evaluate_model(knn_model1, scaler, train_features, train_labels, test_features, test_labels)\n",
    "KNN_acc_score_MinMax = train_and_evaluate_model(knn_model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "KNN_acc_score_Robust = train_and_evaluate_model(knn_model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "SVC_acc_score_Scalar = train_and_evaluate_model(svm_svc_model1, scaler, train_features, train_labels, test_features, test_labels)\n",
    "SVC_acc_score_MinMax = train_and_evaluate_model(svm_svc_model2, min_max_scaler, train_features, train_labels, test_features, test_labels)\n",
    "SVC_acc_score_Robust = train_and_evaluate_model(svm_svc_model3, robust_scaler, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_accuracy_titanic_compare"
=======
    "model.fit(train_features_Scalar, train_labels)\n",
    "model2.fit(train_features_MinMax, train_labels)\n",
    "model3.fit(train_features_Robust, train_labels)"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 155,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "('LogisticRegression - MinMaxScaler', 0.9784688995215312)\n"
=======
      "Accuracy Scalar: 0.9641148325358851\n",
      "Accuracy MinMax: 0.9641148325358851\n",
      "Accuracy Robust: 0.8229665071770335\n"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#For the contest ;)\n",
    "max_key_value_pair = max(model_accuracy_titanic_compare.items(), key=lambda x: x[1])\n",
    "print(max_key_value_pair)"
=======
    "# print(model.score(train_features, train_labels)) #I Switched to the metric module for accuracy_score\n",
    "y_predict_Scalar = model.predict(test_features_Scalar)\n",
    "y_predict_MinMax = model.predict(test_features_MinMax)\n",
    "y_predict_Robust = model.predict(test_features_Robust)\n",
    "\n",
    "LR_model_acc_score_Scalar = accuracy_score(test_labels, y_predict_Scalar)\n",
    "LR_model_acc_score_MinMax = accuracy_score(test_labels, y_predict_MinMax)\n",
    "LR_model_acc_score_Robust = accuracy_score(test_labels, y_predict_Robust)\n",
    "\n",
    "model_accuracy_titanic_compare[\"Logistic Rregression model Scalar:\"] = LR_model_acc_score_Scalar\n",
    "model_accuracy_titanic_compare[\"Logistic Rregression model MinMax:\"] = LR_model_acc_score_MinMax\n",
    "model_accuracy_titanic_compare[\"Logistic Rregression model Robust:\"] = LR_model_acc_score_Robust\n",
    "print(f\"Accuracy Scalar: {LR_model_acc_score_Scalar}\")\n",
    "print(f\"Accuracy MinMax: {LR_model_acc_score_MinMax}\")\n",
    "print(f\"Accuracy Robust: {LR_model_acc_score_Robust}\")"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42201752  1.23270086  0.52596512  0.0671699  -0.50784064  0.03996974]]\n"
     ]
    }
   ],
   "source": [
    "#lets see the coefficents -  Age, Sex_binary, \"Pclass_1\",\"Pclass_2\", \"Pclass_3\", Fare\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients represent the relationship between each feature (variable) and the log-odds of the target event\n",
    "\n",
    "A positive coefficient means that an increase in the feature's value is associated with a higher likelihood of survival.\n",
    "\n",
    "A negative coefficient means that an increase in the feature's value is associated with a lower likelihood of survival.\n",
    "\n",
    "- Age =        -0.42201752   \n",
    "- Sex_binary =  1.23270086      \n",
    "- PClass_1 =    0.52596512 \n",
    "- PClass_2 =    0.0671699   \n",
    "- PClass_3 =   -0.50784064\n",
    "- Fare =        0.03996974\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model2 = LogisticRegression()\n",
    "# model3 = LogisticRegression()\n",
    "\n",
    "# model.fit(train_features_Scalar, train_labels)\n",
    "# model2.fit(train_features_MinMax, train_labels)\n",
    "# model3.fit(train_features_Robust, train_labels)\n",
    "\n",
    "# # print(model.score(train_features, train_labels)) #I Switched to the metric module for accuracy_score\n",
    "# y_predict_Scalar = model.predict(test_features_Scalar)\n",
    "# y_predict_MinMax = model.predict(test_features_MinMax)\n",
    "# y_predict_Robust = model.predict(test_features_Robust)\n",
    "\n",
    "# LR_model_acc_score_Scalar = accuracy_score(test_labels, y_predict_Scalar)\n",
    "# LR_model_acc_score_MinMax = accuracy_score(test_labels, y_predict_MinMax)\n",
    "# LR_model_acc_score_Robust = accuracy_score(test_labels, y_predict_Robust)\n",
    "\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model Scalar:\"] = LR_model_acc_score_Scalar\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model MinMax:\"] = LR_model_acc_score_MinMax\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model Robust:\"] = LR_model_acc_score_Robust\n",
    "# print(f\"Accuracy Scalar: {LR_model_acc_score_Scalar}\")\n",
    "# print(f\"Accuracy MinMax: {LR_model_acc_score_MinMax}\")\n",
    "# print(f\"Accuracy Robust: {LR_model_acc_score_Robust}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_predict = np.array([Jack, Rose, Dom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "passenger_predict = scaler.transform(passenger_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That warning again?.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.88575431 0.11424569]\n",
      " [0.05074167 0.94925833]\n",
      " [0.75688652 0.24311348]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#I remember when I did this 2 years ago, we used Jack and Rose then ourselves to make predictions on the model and we mad ethem in a np.array\n",
    "Jack = np.array([20.0, 0.0, 0.0, 0.0, 1.0, 8.0500])\n",
    "Rose = np.array([17.0, 1.0, 1.0, 0.0, 0.0, 71.2833])\n",
    "Dom = np.array([29.0,  0.0, 0.0, 1.0, 0.0, 30.0708])\n",
    "\n",
    "passenger_predict = np.array([Jack, Rose, Dom])\n",
    "\n",
    "passenger_predict = scaler.transform(passenger_predict)\n",
    "\n",
    "#prediction time! My favorite part\n",
    "# Make survival predictions!\n",
    "print(model.predict(passenger_predict)) #This will print a 1 or 0 for surivied or did not survive \n",
    "print(model.predict_proba(passenger_predict)) #this will give us how likely for each option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jack had an 88.5% of NOT surviving based on the data. \n",
    "- Rose had a 95% chance of surviving. \n",
    "- Dom would of had a 75.9% chance of NOT surviving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Decision Tree model\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "# #does not need normalized data\n",
    "# tree_model.fit(train_features_Scalar, train_labels)\n",
    "# y_predict = tree_model.predict(test_features_Scalar)\n",
=======
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does not need normalized data\n",
    "tree_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9617224880382775\n"
     ]
    }
   ],
   "source": [
    "y_predict = tree_model.predict(test_features_Scalar)\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "# tree_model_acc_score = accuracy_score(test_labels, y_predict)\n",
    "# model_accuracy_titanic_compare[\"Decision Tree model:\"] = tree_model_acc_score\n",
    "# print(f\"Accuracy: {tree_model_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 115,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.8975     0.1025    ]\n",
      " [0.02       0.98      ]\n",
      " [0.67721519 0.32278481]]\n"
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(tree_model1.predict(passenger_predict))\n",
    "print(tree_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC_model = RandomForestClassifier(n_estimators=90, criterion='gini', max_depth=5)\n",
=======
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_model = RandomForestClassifier(n_estimators=90, criterion='gini', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=90)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=90)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=90)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RFC = RFC_model.predict(test_features_Scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9138755980861244\n"
     ]
    }
   ],
   "source": [
    "#Now it should of predicted if it thinks the people in the test_features dataset survived. Lets compare that to our information of their actual survival rates\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "# RFC_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_RFC = RFC_model.predict(test_features_Scalar)\n",
    "\n",
    "# #Now it should of predicted if it thinks the people in the test_features dataset survived. Lets compare that to our information of their actual survival rates\n",
    "\n",
    "# rfl_acc = accuracy_score(test_labels, y_predict_RFC)\n",
    "\n",
    "# model_accuracy_titanic_compare[\"Random Forrect Classifier model:\"] = rfl_acc\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(test_labels, y_predict_RFC))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 120,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
<<<<<<< HEAD
      "[[0.85403593 0.14596407]\n",
      " [0.04778948 0.95221052]\n",
      " [0.77921021 0.22078979]]\n"
=======
      "[[0.86725437 0.13274563]\n",
      " [0.02468284 0.97531716]\n",
      " [0.82880917 0.17119083]]\n"
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(RFC_model1.predict(passenger_predict))\n",
    "print(RFC_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Classification\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We should not need to do much for this one\n",
    "# nb_model = GaussianNB()\n",
=======
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We should not need to do much for this one\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7655502392344498\n"
     ]
    }
   ],
   "source": [
    "y_predict_NB = nb_model.predict(test_features_Scalar)\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "# nb_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_NB = nb_model.predict(test_features_Scalar)\n",
    "\n",
    "# NB_acc_score = accuracy_score(test_labels, y_predict_NB)\n",
    "# model_accuracy_titanic_compare[\"Naive Bayes Classifier model:\"] = NB_acc_score\n",
    "# print(f\"Accuracy: {NB_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
=======
   "execution_count": 124,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.98184197 0.01815803]\n",
      " [0.00758405 0.99241595]\n",
      " [0.8395652  0.1604348 ]]\n"
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(nb_model1.predict(passenger_predict))\n",
    "print(nb_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model = KNeighborsClassifier(n_neighbors=2) \n",
=======
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301435406698564"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = knn_model.predict(test_features_Scalar)\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "# knn_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict = knn_model.predict(test_features_Scalar)\n",
    "\n",
    "# knn_acc = accuracy_score(test_labels, y_predict)\n",
    "# model_accuracy_titanic_compare[\"K Nearest Neighbor model:\"] = knn_acc\n",
    "# knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.66666667 0.33333333]\n",
      " [0.         1.        ]\n",
      " [1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(knn_model1.predict(passenger_predict))\n",
    "print(knn_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Classifer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_svc_model = svm.SVC(kernel='poly', C=1.5) \n",
=======
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_svc_model = svm.SVC(kernel='poly', C=1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.5, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.5, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1.5, kernel='poly')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_svc_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665071770334929"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_svm = svm_svc_model.predict(test_features_Scalar)\n",
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
    "\n",
    "# svm_svc_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_svm = svm_svc_model.predict(test_features_Scalar)\n",
    "\n",
    "# svm_acc = accuracy_score(test_labels, y_predict_svm)\n",
    "# model_accuracy_titanic_compare[\"Support Vector Classifier model:\"] = svm_acc\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(svm_svc_model1.predict(passenger_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral Networks - Pytorch"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cpu'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "#What version am I on?\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 133,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_pre_normalized = train[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "train_labels_pre_normalized = train[\"Survived\"]\n",
    "test_features_pre_normalized = test[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "test_labels_pre_normalized = gender_submission[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 134,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "train_features_pt = torch.tensor(train_features_pre_normalized.values).float()\n",
    "# train_labels = torch.tensor(train_labels_pre_normalized.values).float()\n",
    "test_features_pt = torch.tensor(test_features_pre_normalized.values).float()\n",
    "# test_labels = torch.tensor(test_labels_pre_normalized.values).float()\n",
    "\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "train_labels_np = train_labels.values\n",
    "test_labels_np = test_labels.values\n",
    "\n",
    "# Convert to PyTorch tensors with explicit dtype\n",
    "train_labels_pt = torch.tensor(train_labels_np, dtype=torch.long)\n",
    "test_labels_pt = torch.tensor(test_labels_np, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_features_pt, train_labels_pt)\n",
    "test_dataset = TensorDataset(test_features_pt, test_labels_pt)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 135,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TitanicNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 10  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived\n",
    "\n",
    "# Create the network\n",
    "PyTorchmodel = TitanicNN(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 136,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PyTorchmodel.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.3244384356907437\n",
      "Epoch 2/100, Loss: 1.7025361401694161\n",
      "Epoch 3/100, Loss: 1.2814125886985235\n",
      "Epoch 4/100, Loss: 0.9546120890549251\n",
      "Epoch 5/100, Loss: 0.7498433717659542\n",
      "Epoch 6/100, Loss: 0.6614907724516732\n",
      "Epoch 7/100, Loss: 0.6348223728793008\n",
      "Epoch 8/100, Loss: 0.6240692777293069\n",
      "Epoch 9/100, Loss: 0.60822594165802\n",
      "Epoch 10/100, Loss: 0.5996705719402858\n",
      "Epoch 11/100, Loss: 0.5898275928837913\n",
      "Epoch 12/100, Loss: 0.5785557883126395\n",
      "Epoch 13/100, Loss: 0.5728891768625805\n",
      "Epoch 14/100, Loss: 0.5693911888769695\n",
      "Epoch 15/100, Loss: 0.5660196244716644\n",
      "Epoch 16/100, Loss: 0.5642924734524318\n",
      "Epoch 17/100, Loss: 0.5650203313146319\n",
      "Epoch 18/100, Loss: 0.560883913721357\n",
      "Epoch 19/100, Loss: 0.5586670083659036\n",
      "Epoch 20/100, Loss: 0.5558800271579197\n",
      "Epoch 21/100, Loss: 0.5529915051800864\n",
      "Epoch 22/100, Loss: 0.5516158789396286\n",
      "Epoch 23/100, Loss: 0.5489045573132378\n",
      "Epoch 24/100, Loss: 0.5460995244128364\n",
      "Epoch 25/100, Loss: 0.5427071707589286\n",
      "Epoch 26/100, Loss: 0.540960933480944\n",
      "Epoch 27/100, Loss: 0.538470025573458\n",
      "Epoch 28/100, Loss: 0.5370760432311467\n",
      "Epoch 29/100, Loss: 0.5334002907787051\n",
      "Epoch 30/100, Loss: 0.5310887885945184\n",
      "Epoch 31/100, Loss: 0.5279971808195114\n",
      "Epoch 32/100, Loss: 0.525890263063567\n",
      "Epoch 33/100, Loss: 0.5245210698672703\n",
      "Epoch 34/100, Loss: 0.5266294351645878\n",
      "Epoch 35/100, Loss: 0.5179945251771382\n",
      "Epoch 36/100, Loss: 0.5147015345948083\n",
      "Epoch 37/100, Loss: 0.51335352233478\n",
      "Epoch 38/100, Loss: 0.5101308886493955\n",
      "Epoch 39/100, Loss: 0.5096650762217385\n",
      "Epoch 40/100, Loss: 0.515612033861024\n",
      "Epoch 41/100, Loss: 0.5062625450747353\n",
      "Epoch 42/100, Loss: 0.5025439837149211\n",
      "Epoch 43/100, Loss: 0.5003145273242678\n",
      "Epoch 44/100, Loss: 0.5002100403819766\n",
      "Epoch 45/100, Loss: 0.49751567414828707\n",
      "Epoch 46/100, Loss: 0.5000668827976499\n",
      "Epoch 47/100, Loss: 0.49500695935317446\n",
      "Epoch 48/100, Loss: 0.49186563917568754\n",
      "Epoch 49/100, Loss: 0.48996034477438244\n",
      "Epoch 50/100, Loss: 0.48807077961308615\n",
      "Epoch 51/100, Loss: 0.4851357936859131\n",
      "Epoch 52/100, Loss: 0.4878670083624976\n",
      "Epoch 53/100, Loss: 0.4817428375993456\n",
      "Epoch 54/100, Loss: 0.4827024149043219\n",
      "Epoch 55/100, Loss: 0.480351916381291\n",
      "Epoch 56/100, Loss: 0.4771116716521127\n",
      "Epoch 57/100, Loss: 0.4773880881922586\n",
      "Epoch 58/100, Loss: 0.4752830926861082\n",
      "Epoch 59/100, Loss: 0.4757626141820635\n",
      "Epoch 60/100, Loss: 0.47470272864614216\n",
      "Epoch 61/100, Loss: 0.47268799798829214\n",
      "Epoch 62/100, Loss: 0.46818077138492037\n",
      "Epoch 63/100, Loss: 0.4687960424593517\n",
      "Epoch 64/100, Loss: 0.4699324816465378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Loss: 0.46702614639486584\n",
      "Epoch 66/100, Loss: 0.4653642773628235\n",
      "Epoch 67/100, Loss: 0.474730555500303\n",
      "Epoch 68/100, Loss: 0.470830574631691\n",
      "Epoch 69/100, Loss: 0.46100684787545887\n",
      "Epoch 70/100, Loss: 0.46478661469050814\n",
      "Epoch 71/100, Loss: 0.4638481991631644\n",
      "Epoch 72/100, Loss: 0.4609543872731073\n",
      "Epoch 73/100, Loss: 0.4648556240967342\n",
      "Epoch 74/100, Loss: 0.46284822693892885\n",
      "Epoch 75/100, Loss: 0.46535730361938477\n",
      "Epoch 76/100, Loss: 0.4571969338825771\n",
      "Epoch 77/100, Loss: 0.45695402153900694\n",
      "Epoch 78/100, Loss: 0.4596028221505029\n",
      "Epoch 79/100, Loss: 0.46221618567194256\n",
      "Epoch 80/100, Loss: 0.45845828524657656\n",
      "Epoch 81/100, Loss: 0.45746306010654997\n",
      "Epoch 82/100, Loss: 0.4576763468129294\n",
      "Epoch 83/100, Loss: 0.4588229443345751\n",
      "Epoch 84/100, Loss: 0.45609777101448606\n",
      "Epoch 85/100, Loss: 0.45282922259398867\n",
      "Epoch 86/100, Loss: 0.45391458911555155\n",
      "Epoch 87/100, Loss: 0.46139679849147797\n",
      "Epoch 88/100, Loss: 0.45156484842300415\n",
      "Epoch 89/100, Loss: 0.45530928671360016\n",
      "Epoch 90/100, Loss: 0.45130048266478945\n",
      "Epoch 91/100, Loss: 0.45045111434800283\n",
      "Epoch 92/100, Loss: 0.45277627238205503\n",
      "Epoch 93/100, Loss: 0.4543914667197636\n",
      "Epoch 94/100, Loss: 0.45416288290705\n",
      "Epoch 95/100, Loss: 0.45418139014925274\n",
      "Epoch 96/100, Loss: 0.4533994793891907\n",
      "Epoch 97/100, Loss: 0.45488046535423826\n",
      "Epoch 98/100, Loss: 0.4533383675983974\n",
      "Epoch 99/100, Loss: 0.45011145940848757\n",
      "Epoch 100/100, Loss: 0.4529376711164202\n"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "num_epochs = 100  # adjust this\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmuElEQVR4nO3de5SddX3v8fdn9m1mz0xmJjOTEHIhiCBQFdQcxIoKogjUI7V6FKQWPbpou7Ream3V49LW2i5bT613PVQpeo6gHpTKqSikiqAilIDI/RJCMAkhmdwmc7/s/T1/7GeGzbDnkmR29mT257XWXpn9ey7797BZ85nf5fk9igjMzMymaqh1BczMbGFyQJiZWUUOCDMzq8gBYWZmFTkgzMysIgeEmZlV5IAwq1OSrpD0yVrXwxYuB4QdsSRtlvSqWtdjPkj6a0ljkvrLXvtqXS+rbw4Is4XjOxHRUvZqr3WFrL45IGzRkZST9FlJTySvz0rKJdu6JP27pH2S9kj6uaSGZNtfSdomqU/SQ5LOrnDuF0t6UlKqrOz1ku5Ofj5N0gZJ+yXtkPSZebqmkPQeSZsk7ZL06bJ6N0j6qKTHJe2U9E1JbWXHniHpluSat0h6W9mpOyT9MLnm2yQdNx/1tcXBAWGL0f8ATgdOBU4BTgM+mmz7ALAV6AaWAx8BQtJzgHcD/yUiWoHXAJunnjgibgMGgFeWFb8FuDL5+XPA5yJiCXAc8N15vK7XA+uAFwIXAP89KX9b8joLeBbQAnwRQNIxwI+AL1C65lOBu8rOeSHwN0AHsBH4u3msrx3hHBC2GF0MfCIidkZED6VfgG9Nto0BK4BjImIsIn4epQXJCkAOOFlSJiI2R8Sj05z/KuAiAEmtwPlJ2cT5ny2pKyL6I+LWA6j3m5K/8ideN07Z/g8RsScifgt8dqIOyfV+JiI2RUQ/8GHgQklpSuH1HxFxVXK9uyPirrJzXhMR/xkR48C3KAWIGeCAsMXpaODxsvePJ2UAn6b0l/INSXfNhwAiYiPwPuCvgZ2Svi3paCq7EviDpNvqD4A7I2Li894BnAA8KOl2Sa89gHp/NyLay15nTdm+ZZprqnS9aUotpNXAdEEH8GTZz4OUWh9mgAPCFqcngGPK3q9JyoiIvoj4QEQ8C3gd8OcTYw0RcWVEnJEcG8A/VDp5RNxP6ZfweTy9e4mIeCQiLgKWJcdfLal5nq5rdaVrovL1jgM7KIWKxxXsoDgg7EiXkdRY9kpT6u75qKRuSV3Ax4D/AyDptZKeLUlAL6WupaKk50h6ZdIqGAaGgOIMn3sl8F7g5cD/nSiU9IeSuiOiCOxLimc6z4H4oKQOSauTz/5OUn4V8H5Jx0pqAf6e0oyoiW6jV0l6k6S0pE5Jp85TfWyRc0DYke46Sr/MJ15/DXwS2ADcDdwD3JmUARwP/AfQD/wK+HJE3Ehp/OFTwC5K3S7LKPXlT+cq4BXATyNiV1n5ucB9kvopDVhfGBFDAMm9DS+b4ZxvnnIfRL+kZWXbfwDcQWmQ+YfA15Pyy4H/DdwMPEYp4P4MIBmvOJ/S4Pye5NhTZqiD2ST5gUFmC5+kAI5PxkrMDgu3IMzMrCIHhJmZVeQuJjMzq8gtCDMzqyhd6wrMp66urli7dm2tq2FmdsS44447dkVEd6Vtiyog1q5dy4YNG2pdDTOzI4akx6fb5i4mMzOryAFhZmYVOSDMzKwiB4SZmVXkgDAzs4ocEGZmVpEDwszMKnJAAF/4ySPc9HBPrathZragOCCAr970KDc7IMzMnsYBAeRzaQZHx2tdDTOzBcUBATRnUwyMFGpdDTOzBcUBAeSzbkGYmU3lgACac25BmJlNVbWAkLRa0o2S7pd0n6T3VtjnYkl3S7pH0i2STinbtjkpv0tSVZdodQvCzOyZqrnc9zjwgYi4U1IrcIek9RFxf9k+jwGviIi9ks4DLgNeXLb9rIjYVcU6AqUWxLZ9bkGYmZWrWkBExHZge/Jzn6QHgJXA/WX73FJ2yK3AqmrVZyb5bJrBEbcgzMzKHZYxCElrgRcAt82w2zuAH5W9D+AGSXdIunSGc18qaYOkDT09B3cvQ3M2xcCoWxBmZuWq/kQ5SS3A94D3RcT+afY5i1JAnFFWfEZEbJO0DFgv6cGIuHnqsRFxGaWuKdatWxcHU0ffB2Fm9kxVbUFIylAKh29FxPen2ef5wNeACyJi90R5RGxL/t0JXAOcVq16NmdTjBWC0fFitT7CzOyIU81ZTAK+DjwQEZ+ZZp81wPeBt0bEw2XlzcnANpKagXOAe6tV13y21JByK8LM7CnV7GJ6KfBW4B5JdyVlHwHWAETEV4GPAZ3Al0t5wnhErAOWA9ckZWngyoj4cbUq2pxLATAwWqA9X61PMTM7slRzFtMvAM2yzzuBd1Yo3wSc8swjqmOyBeGZTGZmk3wnNU9vQZiZWYkDArcgzMwqcUAAzUlAuAVhZvYUBwSQT7qYPIvJzOwpDgjKWhBe0dXMbJIDArcgzMwqcUAA+Uwyi8ktCDOzSQ4IIJ1qIJducAvCzKyMAyLRnEsz4IAwM5vkgEjksykG3cVkZjbJAZFozroFYWZWzgGRyOdSDPpGOTOzSQ6IRHM2zYCX2jAzm+SASOSzbkGYmZVzQCQ8i8nM7OkcEAnPYjIzezoHRMItCDOzp6vmM6lXS7pR0v2S7pP03gr7SNLnJW2UdLekF5Ztu0TSI8nrkmrVc0I+m2J4rEihGNX+KDOzI0I1n0k9DnwgIu6U1ArcIWl9RNxfts95wPHJ68XAV4AXS1oKfBxYB0Ry7LURsbdalZ1Y0XVwdJzWxky1PsbM7IhRtRZERGyPiDuTn/uAB4CVU3a7APhmlNwKtEtaAbwGWB8Re5JQWA+cW626QvmKrh6HMDODwzQGIWkt8ALgtimbVgJbyt5vTcqmK6907kslbZC0oaen56Dr+NQzITwOYWYGhyEgJLUA3wPeFxH75/v8EXFZRKyLiHXd3d0HfZ581i0IM7NyVQ0ISRlK4fCtiPh+hV22AavL3q9KyqYrr5rmnFsQZmblqjmLScDXgQci4jPT7HYt8EfJbKbTgd6I2A5cD5wjqUNSB3BOUlY1bkGYmT1dNWcxvRR4K3CPpLuSso8AawAi4qvAdcD5wEZgEHh7sm2PpL8Fbk+O+0RE7KliXZ9qQfheCDMzoIoBERG/ADTLPgG8a5ptlwOXV6FqFU22IHw3tZkZ4DupJ03OYnILwswMcEBM8n0QZmZP54BIZFMNpBvkWUxmZgkHREKSnwlhZlbGAVGmOeenypmZTXBAlHELwszsKQ6IMn4mhJnZUxwQZfxUOTOzpzggyjRn3YIwM5vggCiTz6U9BmFmlnBAlGnOpjyLycws4YAok8+6BWFmNsEBUaY5l2JgdJzSGoJmZvXNAVEmn00TAcNjxVpXxcys5hwQZZqTBfs8k8nMzAHxNPlkyW/fC2Fm5oB4muasWxBmZhMcEGXyyWNHBx0QZmbVe+SopMuB1wI7I+K5FbZ/ELi4rB4nAd3J86g3A31AARiPiHXVqme5yRaEu5jMzKragrgCOHe6jRHx6Yg4NSJOBT4M3BQRe8p2OSvZfljCAcrGINyCMDOrXkBExM3Anll3LLkIuKpadZmryVlMbkGYmdV+DEJSnlJL43tlxQHcIOkOSZfOcvylkjZI2tDT03NIdXELwszsKTUPCOC/Ar+c0r10RkS8EDgPeJekl093cERcFhHrImJdd3f3IVXkqfsg3IIwM1sIAXEhU7qXImJb8u9O4BrgtMNRkcZ0CgkGvWCfmVltA0JSG/AK4AdlZc2SWid+Bs4B7j0c9WloEPlMyi0IMzOqO831KuBMoEvSVuDjQAYgIr6a7PZ64IaIGCg7dDlwjaSJ+l0ZET+uVj2nyufSXvLbzIwqBkREXDSHfa6gNB22vGwTcEp1ajW71sY0fcMOCDOzhTAGsaC0N2XYNzRa62qYmdWcA2KK9nyWfYNjta6GmVnNOSCmaG/K0DvkgDAzc0BMsaQpQ69bEGZmDoip2vMZ+kbGGSv4qXJmVt8cEFO0N2UA2O9uJjOrcw6IKdrzWQCPQ5hZ3XNATNGWtCD2OSDMrM45IKZoy5cCwgPVZlbvHBBTtE+2IHyznJnVNwfEFJNjEG5BmFmdc0BMsaSxtDyVxyDMrN45IKZIpxpozaW93IaZ1T0HRAVt+YzvgzCzuueAqKCtKeMuJjOrew6ICtrzGfYNehaTmdU3B0QF7U1ZtyDMrO5VLSAkXS5pp6SKz5OWdKakXkl3Ja+PlW07V9JDkjZK+lC16jgdj0GYmVW3BXEFcO4s+/w8Ik5NXp8AkJQCvgScB5wMXCTp5CrW8xnamjLsGxwjIg7nx5qZLShVC4iIuBnYcxCHngZsjIhNETEKfBu4YF4rN4v2pgzjxWBgtHA4P9bMbEGp9RjESyT9RtKPJP1OUrYS2FK2z9akrCJJl0raIGlDT0/PvFSqPVmPyQPVZlbPahkQdwLHRMQpwBeAfzuYk0TEZRGxLiLWdXd3z0vF2pq85LeZWc0CIiL2R0R/8vN1QEZSF7ANWF2266qk7LCZWPLb6zGZWT2rWUBIOkqSkp9PS+qyG7gdOF7SsZKywIXAtYezbpNdTG5BmFkdS89lJ0nNwFBEFCWdAJwI/Cgipv0NKukq4EygS9JW4ONABiAivgq8EfhTSePAEHBhlKYNjUt6N3A9kAIuj4j7DvYCD8ZEQLiLyczq2ZwCArgZeJmkDuAGSn/lvxm4eLoDIuKimU4YEV8EvjjNtuuA6+ZYt3nXnoxBeME+M6tnc+1iUkQMAn8AfDki/hvwO7Mcc8RqzDSQTTX4oUFmVtfmHBCSXkKpxfDDpCxVnSrVniTa8hkPUptZXZtrQLwP+DBwTUTcJ+lZwI1Vq9UC0N6U8RiEmdW1OY1BRMRNwE0AkhqAXRHxnmpWrNZKK7o6IMysfs2pBSHpSklLktlM9wL3S/pgdatWW34mhJnVu7l2MZ0cEfuB3wd+BBwLvLValVoI2pqy9HqpDTOrY3MNiIykDKWAuDa5/2FRL3XanvcYhJnVt7kGxP8CNgPNwM2SjgH2V6tSC0FbU4aB0QKj48VaV8XMrCbmFBAR8fmIWBkR50fJ48BZVa5bTfluajOrd3MdpG6T9JmJZbUl/ROl1sSiNblgnwPCzOrUXLuYLgf6gDclr/3Av1arUgtBe35iyW8PVJtZfZrrWkzHRcQbyt7/jaS7qlCfBWOiBeF7IcysXs21BTEk6YyJN5JeSmkF1kWr3QFhZnVuri2IPwG+Kakteb8XuKQ6VVoYPEhtZvVurktt/AY4RdKS5P1+Se8D7q5i3WqqtTGD5IcGmVn9OqAnyiWPCZ24/+HPq1CfBSPVIFpzad9NbWZ161AeOap5q8UC1Z7PugVhZnXrUAJixqU2JF0uaaeke6fZfrGkuyXdI+kWSaeUbduclN8lacMh1PGQdOQz7PUgtZnVqRnHICT1UTkIBDTNcu4rKD1S9JvTbH8MeEVE7JV0HnAZ8OKy7WdFxK5ZPqOqOltyPNk7XMsqmJnVzIwBERGtB3viiLhZ0toZtt9S9vZWYNXBfla1dLVkuXdbb62rYWZWE4fSxTSf3kFpGfEJAdwg6Q5Jl9aoTnS15Ng9MEqxuKgXrjUzq2iu90FUjaSzKAXEGWXFZ0TENknLgPWSHoyIm6c5/lLgUoA1a9bMa926WnIUikHv0Bgdzdl5PbeZ2UJX0xaEpOcDXwMuiIjdE+URsS35dydwDXDadOeIiMsiYl1ErOvu7p7X+nW15gDY1T8yr+c1MzsS1CwgJK0Bvg+8NSIeLitvltQ68TNwDqXHnB52XUmroccBYWZ1qGpdTJKuAs4EuiRtBT4OZAAi4qvAx4BO4MuSAMYjYh2wHLgmKUsDV0bEj6tVz5k81YLwzXJmVn+qFhARcdEs298JvLNC+SbglGcecfh1tSQB0ecWhJnVn4Uyi2lBam/KkGqQxyDMrC45IGbQ0CA6m7PsdheTmdUhB8QsulpybkGYWV1yQMyisyXrgDCzuuSAmEV3S86zmMysLjkgZtHVmqOnf4QIL7dhZvXFATGLrpYso+NF+kfGa10VM7PDygExi8l7IdzNZGZ1xgExi84Wr8dkZvXJATGLrpbSeky+m9rM6o0DYhbdbkGYWZ1yQMxiaXMWCXo8BmFmdcYBMYt0qoGOfJbdbkGYWZ1xQMxBl++mNrM65ICYg85m301tZvXHATEHXa1esM/M6o8DYg66WrKe5mpmdccBMQddLTkGRgsMjRZqXRUzs8OmqgEh6XJJOyXdO812Sfq8pI2S7pb0wrJtl0h6JHldUs16zsb3QphZPap2C+IK4NwZtp8HHJ+8LgW+AiBpKfBx4MXAacDHJXVUtaYz6Jy4m9oBYWZ1pKoBERE3A3tm2OUC4JtRcivQLmkF8BpgfUTsiYi9wHpmDpqq8oJ9ZlaPaj0GsRLYUvZ+a1I2XfkzSLpU0gZJG3p6eqpSya5WdzGZWf2pdUAcsoi4LCLWRcS67u7uqnxGZ7MX7DOz+lPrgNgGrC57vyopm668JhozKVob0+wecBeTmdWPWgfEtcAfJbOZTgd6I2I7cD1wjqSOZHD6nKSsZrpbSo8eNTOrF+lqnlzSVcCZQJekrZRmJmUAIuKrwHXA+cBGYBB4e7Jtj6S/BW5PTvWJiJhpsLvqulpy9LiLyczqSFUDIiIummV7AO+aZtvlwOXVqNfBWNXRxK827a51NczMDptadzEdMY7pbGZ77zDDY76b2szqgwNijtZ25QF4fPdgjWtiZnZ4OCDmaG1nMwCbdw/UuCZmZoeHA2KOJgLicQeEmdUJB8QcteUzdOQzPLbLXUxmVh8cEAdgbVezWxBmVjccEAdgbWczm3c5IMysPjggDsDazmae8FRXM6sTDogDMDHV9bd7PA5hZoufA+IAHDMx1dXdTGZWBxwQB+BY3wthZnXEAXEA2vIZ2vMZNvtuajOrAw6IA7S201Ndzaw+OCAO0NrOPJt9s5yZ1QEHxAFa29XME71DnupqZoueA+IAre1sJgK2eKqrmS1yDogDtLZrYiaTA8LMFreqBoSkcyU9JGmjpA9V2P7Pku5KXg9L2le2rVC27dpq1vNArO0s3SzneyHMbLGr2iNHJaWALwGvBrYCt0u6NiLun9gnIt5ftv+fAS8oO8VQRJxarfodrPZ8Npnq6oAws8Wtmi2I04CNEbEpIkaBbwMXzLD/RcBVVazPvDmms9kBYWaLXjUDYiWwpez91qTsGSQdAxwL/LSsuFHSBkm3Svr96T5E0qXJfht6enrmodqzO2FZC/du289YoXhYPs/MrBYWyiD1hcDVEVE+d/SYiFgHvAX4rKTjKh0YEZdFxLqIWNfd3X046sqrT15O79AYv3p092H5PDOzWqhmQGwDVpe9X5WUVXIhU7qXImJb8u8m4Gc8fXyipl5+QjfN2RTX3bO91lUxM6uaagbE7cDxko6VlKUUAs+YjSTpRKAD+FVZWYekXPJzF/BS4P6px9ZKYybF2Sct5/r7nmTc3UxmtkhVLSAiYhx4N3A98ADw3Yi4T9InJL2ubNcLgW9HRJSVnQRskPQb4EbgU+WznxaC85+3gr2DY9y6aU+tq2JmVhVVm+YKEBHXAddNKfvYlPd/XeG4W4DnVbNuh+rM53STz6a47t7tnHF8V62rY2Y27xbKIPURpzGT4pUnLuP6e5+kUIzZDzAzO8I4IA7B+c9bwe6BUW57zLOZzGzxcUAcgjOf001jpoEf3fNkratiZjbvHBCHIJ9Nc/aJy/m3X2/jzt/urXV1zMzmlQPiEH3ovBNZ2pLl4n+5jZsePjx3cpuZHQ4OiEO0emmeq//kdzm2q5l3XHE7392wxYPWZrYoOCDmQXdrjm//8emsW9vBX159Ny/91E/51I8eZOPO/lpXzczsoOnp96cd2datWxcbNmyo2eePFYrccN8Ovn/nVn72cA+FYnDBqUfzF+c8h9VL8zWrl5nZdCTdkax798xtDojq2NU/wuW/eIyv/+IxIuAtL17D6049mlNWtZNqUK2rZ2YGOCBq6sneYf55/cNcfedWCsWgsznLmc9ZxnnPPYqXndBFLp2qdRXNrI45IBaAfYOj3PRwDz99cCc/e6iH3qExWhvTnHPyUbzhRSs5/dhOGtyyMLPDzAGxwIyOF/nlo7v44d3buf7eJ+kbGWfN0jxvWreKlxzXxUkrWslnq7pMlpkZ4IBY0IZGC/z4vu185/YtkyvDNgie1d3C2s5mVrY3srKjiaPbk1dbE0ubs2TTnoBmZodupoDwn6k11pRN8foXrOL1L1jFjv3D3L21l3u39XLfE/vZuneQ2zbtpm9k/BnH5dINLGnK0CAYKwSj40VacmnWduVZ29nM0e1NdOQzdDRnWdqcZVlrju7WRpY0ppHclWVms3NALCDLlzTy6pMbefXJy59W3js0xvbeIZ7YN8S2fcPsGxilb2ScvuExikXIpEUm1UDv0BiP7x5k/f072D0wWvEzcukGli3Jsay1ka6WLM25NM3ZNC2NabpacnS35uhO/l22JEdrzoFiVq8cEEeAtqYMbU0ZTjxqyZyPGR0vsm9olL0DY+zuH6Gnf4SevhF27B9mZ98IO/eP8NiuAQZGCgyOjtM3PM54hTvAGzMNHN3WxIr2Rla0NdHelGFJU4bWxjRLm7N0teRY2pyltTFNSy5NPpt295fZIuGAWKSy6QaWtTayrLURaJ11/4igd2iMnr5SkPT0l0Jkx/5htvcO80TvEL94ZBe9Q2MMjRVmPFd7PsOqjiZWd+RZ1ppjaXOOpc0ZulpyHNXWyFFtjXS15MikHCRmC1lVA0LSucDngBTwtYj41JTtbwM+DWxLir4YEV9Ltl0CfDQp/2REfKOada13kmjPZ2nPZzl++cyBMlYo0jc8zp6BUXb1j7C7f5SBkXH6R8YZGBlnR98wW/YM8fCOPn65cRf7h585hgLQkkvTns+wpDFDcy5FPptGgn2DY+wbHCXVIF52fDdnn7SM045d6ntGzA6zqs1ikpQCHgZeDWwFbgcuKn+2dBIQ6yLi3VOOXQpsANYBAdwBvCgiZlxT+0icxVQPxgpF9g6OTrZIntw/zO7+0VIQDI2yf2iMwdECA6MFisWgPZ+hPZ+lb3iMXz26m5HxIpmUOKqt1M21fEkjLbk0zdkULY1pli8ptUqWtzaSyzSQbhDFgId39HHP1l4efLKPE5a3cO5zj+J5K9s8pmJWplazmE4DNkbEpqQS3wYuAO6f8aiS1wDrI2JPcux64FzgqirV1aook3qqu+u5K9sO6Nih0QK3PLqL2zfvZXvvENv3DXPP1n30J2Mng6Mzd3elGsQxnXlufGgnX/7Zo6xsb+L5q9pYvTTPqo4mlrU20pHPsLQ5S2Om1EKRoDmbpq0pM3nzYkQwkHxWS849s1Yfqvl/+kpgS9n7rcCLK+z3Bkkvp9TaeH9EbJnm2JXVqqgtXE3ZFGeftJyzT1pecftYoUhP3wjbe4fZuX+Y0UKR8UJQjOC4ZS2cvGIJjZkUewdG+cmDO1l//5M8tKOPnzy4k9Hx4oyfnW4QXS05Ug1iV/8II8n+K9ubOGF5C8d1t7CivYkVbY0sa81NTiZY0pSZDBuzI1mt/xT6f8BVETEi6Y+BbwCvPJATSLoUuBRgzZo1819DW9AyqYbJmwhn0tGc5Y0vWsUbX7QKgGIx2JXM7to7MMaewVFGxgoEQED/yDi7+kfY2TdCsRh0teboaskyVgge3tHHQ0/28ctHd08bMtl0w2RgLGvNsXxJIx35bGkiQP8I+wZHObarmVNWtfP8VW3k0imGxwuMjhfJZ1MsTe5fafE0Y6uhagbENmB12ftVPDUYDUBE7C57+zXgH8uOPXPKsT+r9CERcRlwGZTGIA6lwlY/GhrEsiWNLFvSeNDniAj2DY6xvXeYnv4ReofG2D80Nvnv/uEx9g6MsbNvmNs372HPwCgd+SxdLVmWNGa4bdMefnDXEzN+Rj6bYkUy9tKUTVEsBoUIGtOpybGaXLqBQjEYLwYSNKZTNGYayOfStDdlaM9n6GzOcWxXM03Zg2/Z7Owb5ucP76Ixk2LN0jxrOvO0NWUO+ny28FUzIG4Hjpd0LKVf+BcCbynfQdKKiNievH0d8EDy8/XA30vqSN6fA3y4inU1O2CS6GjO0tGcPehz7Ng/zH1P9FIsQi7TQDbVwMDoOHuS+1d29o0kN0kOs3tglAaVxlWGxwrJbK8xRgtFUg0i1SAigrHC9H8nrWxv4uj2RooB44Uio4VgeKzA8FiBsUKRjnyW5UtKXWYT97ukGsQvHtnFHb/dy9Q5LSce1crvPW8Fv/f8FbTns2zZM8iWvYOMjBXJZRpoTKdYUtaKKkawZe8gj+8epH94nLYkwNKpBvYMjLCrf5SI4PRndXJMZ/Os//1Gx4v0Do3Rns942nQVVC0gImJc0rsp/bJPAZdHxH2SPgFsiIhrgfdIeh0wDuwB3pYcu0fS31IKGYBPTAxYmy0my5c0svwQWzERPG0l4EKx9Et/YGSc3qEx9g2NsXP/CJt6+nm0p5/tvcNk0yKdS5NJNdCUTdGUaSDVUPolvSO5ibJveIz+kXGKASetWML7zj6BV528DCF+u2eQTbv6+ekDO/mn9Q/zT+sfno//HE+ztjPPaccunZz+XCwGuwdG6ekbYVd/KUx6h8aAUmgetaSR1UubaG3MkEs30JhJIaAYpf9OI4Uiw6MFhsYKNGZSkysGLF+SY0VyM2hzNs3weIGh0QKbdw9wy8bd/GrTbvYPjfHqk4/itc9fwbq1HezYP8KWvYPsHxrj6PYmjunM092Se0Z34PBYgT0Do/QNj9M/Mkb/SIGIoEGiQaJ891SDyKZLfySMFYqT08Yl0ZorrXYwEeATN6NOtGL3D4/NKVAPlBfrM7NpRQQj48UZB9239w5xw307GCsUWbM0z+qlefLZFCPjRYbHCvQmAbWjb5gIOKYzz5qleZY0Ztg/XGoFjRWKk3fmjxaK/OKRXdz0cA93b93HeDEoJnf5d7aUxoK6WnKTr/Z8hl39I2zZM8jWvUMMjBYYSVpFUGrpSaVlZpqyKRrTKQZHC0nIjDDTI+TbmjK85Fmd5LMp1j+wg75p7umB0rhTUyZFNl2aar1vcPabSg+GBF0tObKpBnr6RhgtFFnWmuM//8erDvJ8XqzPzA6CpFlnZK1oa+KS3107r597XHfLvJ+zkkIx2N0/whO9w2zfN8TQWIGmTIrGTIrlSxo58ajWydbZyHiBX27cxQPb+zi6vZHVHaUxmK37hvjt7kGe6B1iZKzIyHiB8ULQ1vTUYplLGjO0NKZpyaWQSl2BhbL5DaX3pVbO6HiRbKqhtE5aLkUkkyb6k5tTt/cOs713iNHxIt3Jumor2g6+FToTtyDMzOrYTC0Ij+qYmVlFDggzM6vIAWFmZhU5IMzMrCIHhJmZVeSAMDOzihwQZmZWkQPCzMwqWlQ3yknqAR4/gEO6gF1Vqs5CVY/XDPV53fV4zVCf130o13xMRHRX2rCoAuJASdow3R2Ei1U9XjPU53XX4zVDfV53ta7ZXUxmZlaRA8LMzCqq94C4rNYVqIF6vGaoz+uux2uG+rzuqlxzXY9BmJnZ9Oq9BWFmZtNwQJiZWUV1GRCSzpX0kKSNkj5U6/pUi6TVkm6UdL+k+yS9NylfKmm9pEeSfztqXdf5Jikl6deS/j15f6yk25Lv/DuSsrWu43yT1C7pakkPSnpA0ksW+3ct6f3J/9v3SrpKUuNi/K4lXS5pp6R7y8oqfrcq+Xxy/XdLeuHBfm7dBYSkFPAl4DzgZOAiSSfXtlZVMw58ICJOBk4H3pVc64eAn0TE8cBPkveLzXuBB8re/wPwzxHxbGAv8I6a1Kq6Pgf8OCJOBE6hdP2L9ruWtBJ4D7AuIp4LpIALWZzf9RXAuVPKpvtuzwOOT16XAl852A+tu4AATgM2RsSmiBgFvg1cUOM6VUVEbI+IO5Of+yj9wlhJ6Xq/kez2DeD3a1LBKpG0Cvg94GvJewGvBK5OdlmM19wGvBz4OkBEjEbEPhb5dw2kgSZJaSAPbGcRftcRcTOwZ0rxdN/tBcA3o+RWoF3SioP53HoMiJXAlrL3W5OyRU3SWuAFwG3A8ojYnmx6Elheq3pVyWeBvwQmHgvfCeyLiPHk/WL8zo8FeoB/TbrWviapmUX8XUfENuB/Ar+lFAy9wB0s/u96wnTf7bz9jqvHgKg7klqA7wHvi4j95duiNM950cx1lvRaYGdE3FHruhxmaeCFwFci4gXAAFO6kxbhd91B6a/lY4GjgWae2Q1TF6r13dZjQGwDVpe9X5WULUqSMpTC4VsR8f2keMdEkzP5d2et6lcFLwVeJ2kzpe7DV1Lqm29PuiFgcX7nW4GtEXFb8v5qSoGxmL/rVwGPRURPRIwB36f0/S/273rCdN/tvP2Oq8eAuB04PpnpkKU0qHVtjetUFUnf+9eBByLiM2WbrgUuSX6+BPjB4a5btUTEhyNiVUSspfTd/jQiLgZuBN6Y7LaorhkgIp4Etkh6TlJ0NnA/i/i7ptS1dLqkfPL/+sQ1L+rvusx03+21wB8ls5lOB3rLuqIOSF3eSS3pfEr91Cng8oj4u9rWqDoknQH8HLiHp/rjP0JpHOK7wBpKy6O/KSKmDoAd8SSdCfxFRLxW0rMotSiWAr8G/jAiRmpYvXkn6VRKA/NZYBPwdkp/BC7a71rS3wBvpjRj79fAOyn1ty+q71rSVcCZlJb13gF8HPg3Kny3SVh+kVJ32yDw9ojYcFCfW48BYWZms6vHLiYzM5sDB4SZmVXkgDAzs4ocEGZmVpEDwszMKnJAmB0ASQVJd5W95m3xO0lry1frNKu19Oy7mFmZoYg4tdaVMDsc3IIwmweSNkv6R0n3SPpPSc9OytdK+mmyLv9PJK1JypdLukbSb5LX7yanSkn6l+QZBzdIaqrZRVndc0CYHZimKV1Mby7b1hsRz6N0F+tnk7IvAN+IiOcD3wI+n5R/HrgpIk6htGbSfUn58cCXIuJ3gH3AG6p6NWYz8J3UZgdAUn9EtFQo3wy8MiI2JQskPhkRnZJ2ASsiYiwp3x4RXZJ6gFXlS0AkS7KvTx4Ag6S/AjIR8cnDcGlmz+AWhNn8iWl+PhDlawYV8Dih1ZADwmz+vLns318lP99CaVVZgIspLZ4IpUdE/ilMPj+77XBV0myu/NeJ2YFpknRX2fsfR8TEVNcOSXdTagVclJT9GaWnvH2Q0hPf3p6Uvxe4TNI7KLUU/pTSU9HMFgyPQZjNg2QMYl1E7Kp1Xczmi7uYzMysIrcgzMysIrcgzMysIgeEmZlV5IAwM7OKHBBmZlaRA8LMzCr6/8c2NoynYQ+oAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "plt.plot(range(1, num_epochs+1), losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 91.14832535885168%\n"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "PyTorchmodel.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "model_accuracy_titanic_compare[\"Pytorch Neural Network model:\"] = accuracy\n",
    "print(f'Accuracy on test set: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 140,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict time!!\n",
    "passenger_predict_tensor = torch.tensor(passenger_predict).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.961452841758728, 0.038547173142433167],\n",
       " [0.10855162143707275, 0.891448438167572],\n",
       " [0.759102463722229, 0.24089756608009338]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "# Set the PyTorchmodel to evaluation mode\n",
    "PyTorchmodel.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "# Convert predictions and probabilities to numpy arrays for easy printing\n",
    "predictions_np = predictions.tolist()\n",
    "probabilities_np = probabilities.tolist()\n",
    "\n",
    "# Print results\n",
    "print(predictions_np)\n",
    "probabilities_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 142,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to TensorFlow tensors\n",
    "train_features_tf = tf.convert_to_tensor(train_features.values, dtype=tf.float32)\n",
    "train_labels_tf = tf.convert_to_tensor(train_labels.values, dtype=tf.int64)\n",
    "test_features_tf = tf.convert_to_tensor(test_features.values, dtype=tf.float32)\n",
    "test_labels_tf = tf.convert_to_tensor(test_labels.values, dtype=tf.int64)\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 12  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 143,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the nn\n",
    "model_tf = models.Sequential([\n",
    "    layers.Dense(hidden_size, activation='relu', input_shape=(input_size,)),\n",
    "    layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# model_tf = models.Sequential([\n",
    "#     layers.Dense(hidden_size, activation='relu', input_shape=(input_size,), kernel_regularizer='l2'),\n",
    "#     layers.Dropout(0.3), \n",
    "#     layers.Dense(16, activation='relu', kernel_regularizer='l2'), \n",
    "#     layers.Dense(output_size, activation='softmax')\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 144,
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model here\n",
    "model_tf.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# model_tf.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Assuming labels are not one-hot encoded\n",
    "#                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 9.9353 - accuracy: 0.5948\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.5087 - accuracy: 0.5084\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.4460 - accuracy: 0.4377\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.4894 - accuracy: 0.4321\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 5.5166 - accuracy: 0.4254\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 4.6365 - accuracy: 0.4242\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3.7411 - accuracy: 0.4220\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2.9021 - accuracy: 0.4141\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2.0333 - accuracy: 0.4287\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.2731 - accuracy: 0.4209\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7569 - accuracy: 0.5657\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6734\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6745\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6216 - accuracy: 0.6835\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6813\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6104 - accuracy: 0.6779\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6880\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.6925\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.6902\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6914\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.6947\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6970\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.7026\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6914\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.7003\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6981\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6981\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.6947\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7003\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.6936\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7104\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.6891\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7149\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.6981\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7082\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7149\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7194\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7116\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7104\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7205\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7239\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7273\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7217\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7329\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7363\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7239\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7329\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7441\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7306\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7329\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7441\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7419\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7497\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7508\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7441\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7452\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7520\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7531\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7464\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7520\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7587\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7643\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7643\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7587\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7609\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7553\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7621\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7677\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7621\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7733\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7722\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7677\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7755\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7778\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7643\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7755\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7744\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7789\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7789\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7800\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7722\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7744\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7778\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7778\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7699\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7834\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7845\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7755\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7767\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7710\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7755\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7755\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7800\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7800\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7778\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7845\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7823\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7744\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7856\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7823\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7811\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7811\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7811\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7845\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7834\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7767\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7856\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7834\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7868\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7879\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7868\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7868\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7912\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7935\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7901\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7957\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7868\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7823\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7946\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7868\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7991\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7912\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7912\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7924\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8036\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7924\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8025\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7912\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8013\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8013\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7957\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8002\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7957\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8013\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8025\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8002\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8058\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8025\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7969\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8013\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7946\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8047\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.8070\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7980\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7879\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8036\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8013\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7980\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.8002\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7991\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.8025\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7969\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7946\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.8002\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8025\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7980\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7969\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8013\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8002\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7946\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.8058\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7980\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7980\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8025\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7980\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8002\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7935\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8013\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7991\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7935\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7957\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8025\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7924\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8002\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7957\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7924\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8025\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8013\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8047\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7969\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8070\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7924\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7924\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7946\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7946\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8036\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7980\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8025\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7924\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8002\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7912\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8002\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8002\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8002\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8047\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7924\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8036\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8126\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7969\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7924\n"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "#model train\n",
    "history = model_tf.fit(train_features_tf, train_labels_tf, epochs=200, batch_size=batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.9641\n",
      "Accuracy on test set: 0.9641148447990417\n"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "loss, accuracy = model_tf.evaluate(test_features_tf, test_labels_tf)\n",
    "model_accuracy_titanic_compare[\"Tensorflow Neural Network model:\"] = accuracy\n",
    "print(f'Accuracy on test set: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "[0 1 0]\n",
      "[[0.8361633  0.16383679]\n",
      " [0.01837283 0.98162717]\n",
      " [0.50466055 0.49533945]]\n"
     ]
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "passenger_predict_tf = tf.convert_to_tensor(passenger_predict, dtype=tf.float32)\n",
    "predictions_tf = model_tf.predict(passenger_predict_tf)\n",
    "predicted_classes_tf = tf.argmax(predictions_tf, axis=1).numpy()\n",
    "\n",
    "print(predicted_classes_tf)\n",
    "print(predictions_tf)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Rregression model:': 0.9641148325358851,\n",
       " 'Decision Tree model:': 0.9617224880382775,\n",
       " 'Random Forrect Classifier model:': 0.9138755980861244,\n",
       " 'Naive Bayes Classifier model:': 0.7655502392344498,\n",
       " 'K Nearest Neighbor model:': 0.8301435406698564,\n",
       " 'Support Vector Classifier model:': 0.9665071770334929,\n",
       " 'Pytorch Neural Network model:': 0.9114832535885168,\n",
       " 'Tensorflow Neural Network model:': 0.9641148447990417}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 58efe2290226c39941908dad76119f83bf8d69d1
   "source": [
    "model_accuracy_titanic_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
