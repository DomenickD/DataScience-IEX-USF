{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data minuplations modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import viuslaization models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import normalization modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#import preprocessing train_test_split module\n",
    "# from sklearn.model_selection import train_test_split # Do not need this with the multiple datasets kaggle has given\n",
    "\n",
    "#import machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#import NN models - Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#import NN models - Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#import accuracy_score function from sklearn.metrics to score models better\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into dataframes\n",
    "#data retrieved from kaggle competitions\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "gender_submission = pd.read_csv(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Survived  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q         0  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S         1  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q         0  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S         0  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S         1  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the gender_submission database and the test_df database since they were given by kaggle\n",
    "#but contain incomplete data in comparision to the train dataframe. This merge consolidates for further manipulation\n",
    "test = pd.merge(test_df, gender_submission, on = \"PassengerId\", how=\"inner\")\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to need to apply any column changes to test and train. gender_submissions will be what we apply at the end with passenger IDs matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Pclass_1  Pclass_2  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S         0         0   \n",
       "1      0          PC 17599  71.2833   C85        C         1         0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S         0         0   \n",
       "3      0            113803  53.1000  C123        S         1         0   \n",
       "4      0            373450   8.0500   NaN        S         0         0   \n",
       "\n",
       "   Pclass_3  Sex_binary  \n",
       "0         1           0  \n",
       "1         0           1  \n",
       "2         1           1  \n",
       "3         0           1  \n",
       "4         1           0  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummies variables for PClass to prevent bias toward one number being weighed more than another\n",
    "train = pd.concat([train, pd.get_dummies(train[\"Pclass\"], prefix='Pclass')], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test[\"Pclass\"], prefix='Pclass')], axis=1)\n",
    "\n",
    "# Let's make the sex cloumn into a binary column\n",
    "train['Sex_binary'] = train.Sex.map({\"male\": 0, \"female\": 1}) \n",
    "test['Sex_binary'] = test.Sex.map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to turn the Pclass into its own columns in order to get a better prediction on who will be in what class\n",
    "# train['FirstClass'] = train.Pclass.apply(lambda p: 1 if p == 1 else 0)\n",
    "# test['FirstClass'] = test.Pclass.apply(lambda p: 1 if p == 1 else 0)\n",
    "# train.head()\n",
    "# Now the same thing for second class and then again for third class people. \n",
    "# We need to turn the Pclass into its own columns in order to get a better prediction on who will be in what class\n",
    "# train['SecondClass'] = train.Pclass.apply( lambda p: 1 if p == 2 else 0)\n",
    "# test['SecondClass'] = test.Pclass.apply( lambda p: 1 if p == 2 else 0)\n",
    "# train.head(10)\n",
    "# train['ThirdClass'] = train.Pclass.apply( lambda p: 1 if p == 3 else 0)\n",
    "# test['ThirdClass'] = test.Pclass.apply( lambda p: 1 if p == 3 else 0)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from stories of Titanic that women and children  can be saved in a life raft, but what about men? \n",
    "I think we should address gender and age next as it may help our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could of done this earlier, but in this data, I am not likely to use the following columns right now. I may need them later for further analysis but at present they are just cluttering up my dataset. Lets just drop them for now from each dataframe.\n",
    "\n",
    "Pclass, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
       "0            1         0  22.0      1      0   7.2500         0         0   \n",
       "1            2         1  38.0      1      0  71.2833         1         0   \n",
       "2            3         1  26.0      0      0   7.9250         0         0   \n",
       "3            4         1  35.0      1      0  53.1000         1         0   \n",
       "4            5         0  35.0      0      0   8.0500         0         0   \n",
       "\n",
       "   Pclass_3  Sex_binary  \n",
       "0         1           0  \n",
       "1         0           1  \n",
       "2         1           1  \n",
       "3         0           1  \n",
       "4         1           0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns_to_drop = [\"Pclass\", \"Name\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "columns_to_drop = [\"Pclass\", \"Name\", \"Sex\",  \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "train = train.drop(columns_to_drop, axis = 1)\n",
    "test = test.drop(columns_to_drop, axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.352413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.477990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch  \\\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838   29.699118    0.523008    0.381594   \n",
       "std     257.353842    0.486592   14.526497    1.102743    0.806057   \n",
       "min       1.000000    0.000000    0.420000    0.000000    0.000000   \n",
       "25%     223.500000    0.000000   20.125000    0.000000    0.000000   \n",
       "50%     446.000000    0.000000   28.000000    0.000000    0.000000   \n",
       "75%     668.500000    1.000000   38.000000    1.000000    0.000000   \n",
       "max     891.000000    1.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Pclass_1    Pclass_2    Pclass_3  Sex_binary  \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
       "mean    32.204208    0.242424    0.206510    0.551066    0.352413  \n",
       "std     49.693429    0.428790    0.405028    0.497665    0.477990  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      7.910400    0.000000    0.000000    0.000000    0.000000  \n",
       "50%     14.454200    0.000000    0.000000    1.000000    0.000000  \n",
       "75%     31.000000    0.000000    0.000000    1.000000    1.000000  \n",
       "max    512.329200    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of missing data:\n",
    "- **Missing Completely at Random (MCAR):** No pattern to the missingness.\n",
    "- **Missing at Random (MAR):** Missingness might be related to other observed variables, but not the missing value itself.\n",
    "- **Missing Not at Random (MNAR):** The missingness depends on the value of the missing data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for Handling Missing Values\n",
    "\n",
    "- **Listwise Deletion:** Remove rows containing missing values. Use with caution, especially if you have a large number of missing entries, as you could lose valuable information.\n",
    "- **Pairwise Deletion:** Utilize all available data, but computations might involve different subsets of data.\n",
    "- **Imputation:** Fill in missing values with estimated substitutes. **Common methods:**\n",
    "- **Mean/Median Imputation:** Replace missing values with the mean/median of the column. Suitable for numerical data.\n",
    "- **Mode Imputation:** Replace missing categorical values with the most frequent category.\n",
    "- **Predictive Modeling:** Create a model to predict missing values based on other variables. This can be more sophisticated.\n",
    "\n",
    "\n",
    "This is an exert summary from google's Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Let's fill in the ages with the mean of all ages.\n",
    "train['Age'].fillna(value = round(train['Age'].mean()), inplace = True) #look up .fillna function\n",
    "test['Age'].fillna(value = round(test['Age'].mean()), inplace = True) \n",
    "train[\"Age\"].count() #now we have every row accounted for. \n",
    "test[\"Fare\"].dropna(axis=0, how='any', inplace=True)\n",
    "test['Fare'].fillna(value = round(test['Fare'].mean()), inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    " We were given two datasets so we will split them accordingly. WIth one dataset we would use the train_test_split function from the model selection of sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to focus on training a model on Age, Sex_binary, FirstClass, SecondClass, ThirdClass, \"SibSp\", \"Parch\", \"Fare\"\n",
    "#The goal is to predict whether or not the user survived based on this. \n",
    "train_features = train[[\"Age\", \"Sex_binary\", \"Pclass_1\",\"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "train_labels = train[\"Survived\"]\n",
    "test_features = test[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "test_labels = gender_submission[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an accuracy test key = model , value = accuracy score\n",
    "model_accuracy_titanic_compare = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will normalize the data in preparation for loading and training the model. This allows all weighst to be evenly distriubted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature data so it has mean = 0 and standard deviation = 1\n",
    "scaler = StandardScaler()\n",
    "train_features_Scalar = scaler.fit_transform(train_features)\n",
    "test_features_Scalar = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_features_MinMax = scaler.fit_transform(train_features)\n",
    "test_features_MinMax = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9641148325358851\n"
     ]
    }
   ],
   "source": [
    "# print(model.score(train_features, train_labels)) #I Switched to the metric module for accuracy_score\n",
    "y_predict = model.predict(test_features_Scalar)\n",
    "\n",
    "LR_model_acc_score = accuracy_score(test_labels, y_predict)\n",
    "model_accuracy_titanic_compare[\"Logistic Rregression model:\"] = LR_model_acc_score\n",
    "print(f\"Accuracy: {LR_model_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42201752  1.23270086  0.52596512  0.0671699  -0.50784064  0.03996974]]\n"
     ]
    }
   ],
   "source": [
    "#lets see the coefficents -  Age, Sex_binary, \"Pclass_1\",\"Pclass_2\", \"Pclass_3\", Fare\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients represent the relationship between each feature (variable) and the log-odds of the target event\n",
    "\n",
    "A positive coefficient means that an increase in the feature's value is associated with a higher likelihood of survival.\n",
    "\n",
    "A negative coefficient means that an increase in the feature's value is associated with a lower likelihood of survival.\n",
    "\n",
    "- Age =        -0.42201752   \n",
    "- Sex_binary =  1.23270086      \n",
    "- PClass_1 =    0.52596512 \n",
    "- PClass_2 =    0.0671699   \n",
    "- PClass_3 =   -0.50784064\n",
    "- Fare =        0.03996974\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I remember when I did this 2 years ago, we used Jack and Rose then ourselves to make predictions on the model and we mad ethem in a np.array\n",
    "Jack = np.array([20.0, 0.0, 0.0, 0.0, 1.0, 8.0500])\n",
    "Rose = np.array([17.0, 1.0, 1.0, 0.0, 0.0, 71.2833])\n",
    "Dom = np.array([29.0,  0.0, 0.0, 1.0, 0.0, 30.0708])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_predict = np.array([Jack, Rose, Dom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "passenger_predict = scaler.transform(passenger_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That warning again?.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.88575431 0.11424569]\n",
      " [0.05074167 0.94925833]\n",
      " [0.75688652 0.24311348]]\n"
     ]
    }
   ],
   "source": [
    "#prediction time! My favorite part\n",
    "# Make survival predictions!\n",
    "print(model.predict(passenger_predict)) #This will print a 1 or 0 for surivied or did not survive \n",
    "print(model.predict_proba(passenger_predict)) #this will give us how likely for each option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jack had an 88.5% of NOT surviving based on the data. \n",
    "- Rose had a 95% chance of surviving. \n",
    "- Dom would of had a 75.9% chance of NOT surviving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Decision Tree model\n",
    "\n",
    "We have the option of using DecisionTreeClassifier or DecisionTreeRegressor.\n",
    "\n",
    "We know that we are classifying whether or not someone survived so we should use the DecisionTreeClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does not need normalized data\n",
    "tree_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9617224880382775\n"
     ]
    }
   ],
   "source": [
    "y_predict = tree_model.predict(test_features_Scalar)\n",
    "\n",
    "tree_model_acc_score = accuracy_score(test_labels, y_predict)\n",
    "model_accuracy_titanic_compare[\"Decision Tree model:\"] = tree_model_acc_score\n",
    "print(f\"Accuracy: {tree_model_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.8975     0.1025    ]\n",
      " [0.02       0.98      ]\n",
      " [0.67721519 0.32278481]]\n"
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(tree_model.predict(passenger_predict))\n",
    "print(tree_model.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_model = RandomForestClassifier(n_estimators=90, criterion='gini', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=90)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=90)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=90)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RFC = RFC_model.predict(test_features_Scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8827751196172249\n"
     ]
    }
   ],
   "source": [
    "#Now it should of predicted if it thinks the people in the test_features dataset survived. Lets compare that to our information of their actual survival rates\n",
    "\n",
    "rfl_acc = accuracy_score(test_labels, y_predict_RFC)\n",
    "\n",
    "model_accuracy_titanic_compare[\"Random Forrect Classifier model:\"] = rfl_acc\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, y_predict_RFC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.86193575 0.13806425]\n",
      " [0.03277286 0.96722714]\n",
      " [0.81102691 0.18897309]]\n"
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(RFC_model.predict(passenger_predict))\n",
    "print(RFC_model.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we will go over Naive Bayes for Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We should not need to do much for this one\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7655502392344498\n"
     ]
    }
   ],
   "source": [
    "y_predict_NB = nb_model.predict(test_features_Scalar)\n",
    "\n",
    "NB_acc_score = accuracy_score(test_labels, y_predict_NB)\n",
    "model_accuracy_titanic_compare[\"Naive Bayes Classifier model:\"] = NB_acc_score\n",
    "print(f\"Accuracy: {NB_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[0.98184197 0.01815803]\n",
      " [0.00758405 0.99241595]\n",
      " [0.8395652  0.1604348 ]]\n"
     ]
    }
   ],
   "source": [
    "# passenger_predict\n",
    "print(nb_model.predict(passenger_predict))\n",
    "print(nb_model.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = knn_model.predict(test_features_Scalar)\n",
    "\n",
    "knn_acc = accuracy_score(test_labels, y_predict)\n",
    "model_accuracy_titanic_compare[\"K Nearest Neighbor model:\"] = knn_acc\n",
    "knn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_svc_model = svm.SVC(kernel='poly', C=1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.5, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.5, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1.5, kernel='poly')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_svc_model.fit(train_features_Scalar, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665071770334929"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_svm = svm_svc_model.predict(test_features_Scalar)\n",
    "\n",
    "svm_acc = accuracy_score(test_labels, y_predict_svm)\n",
    "model_accuracy_titanic_compare[\"Support Vector Classifier model:\"] = svm_acc\n",
    "svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral Networks - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cpu'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What version am I on?\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_pre_normalized = train[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "train_labels_pre_normalized = train[\"Survived\"]\n",
    "test_features_pre_normalized = test[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "test_labels_pre_normalized = gender_submission[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_5168\\2508534257.py:2: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  train_features_pt = torch.tensor(train_features_pre_normalized.values).float()\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "train_features_pt = torch.tensor(train_features_pre_normalized.values).float()\n",
    "# train_labels = torch.tensor(train_labels_pre_normalized.values).float()\n",
    "test_features_pt = torch.tensor(test_features_pre_normalized.values).float()\n",
    "# test_labels = torch.tensor(test_labels_pre_normalized.values).float()\n",
    "\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "train_labels_np = train_labels.values\n",
    "test_labels_np = test_labels.values\n",
    "\n",
    "# Convert to PyTorch tensors with explicit dtype\n",
    "train_labels_pt = torch.tensor(train_labels_np, dtype=torch.long)\n",
    "test_labels_pt = torch.tensor(test_labels_np, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_features_pt, train_labels_pt)\n",
    "test_dataset = TensorDataset(test_features_pt, test_labels_pt)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TitanicNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 10  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived\n",
    "\n",
    "# Create the network\n",
    "PyTorchmodel = TitanicNN(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PyTorchmodel.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7728467839104789\n",
      "Epoch 2/100, Loss: 0.6509943391595568\n",
      "Epoch 3/100, Loss: 0.6116829769951957\n",
      "Epoch 4/100, Loss: 0.6091484980923789\n",
      "Epoch 5/100, Loss: 0.6023237960679191\n",
      "Epoch 6/100, Loss: 0.598874398640224\n",
      "Epoch 7/100, Loss: 0.5966017629419055\n",
      "Epoch 8/100, Loss: 0.5954499947173255\n",
      "Epoch 9/100, Loss: 0.5933724769524166\n",
      "Epoch 10/100, Loss: 0.5933330995695931\n",
      "Epoch 11/100, Loss: 0.5910523022924151\n",
      "Epoch 12/100, Loss: 0.588396532194955\n",
      "Epoch 13/100, Loss: 0.5869190373591014\n",
      "Epoch 14/100, Loss: 0.585957910333361\n",
      "Epoch 15/100, Loss: 0.5825032123497554\n",
      "Epoch 16/100, Loss: 0.5807785008634839\n",
      "Epoch 17/100, Loss: 0.578188738652638\n",
      "Epoch 18/100, Loss: 0.5755171009472438\n",
      "Epoch 19/100, Loss: 0.5688919510160174\n",
      "Epoch 20/100, Loss: 0.5619595944881439\n",
      "Epoch 21/100, Loss: 0.5554712755339486\n",
      "Epoch 22/100, Loss: 0.5515387526580265\n",
      "Epoch 23/100, Loss: 0.5513582846948079\n",
      "Epoch 24/100, Loss: 0.5457785299846104\n",
      "Epoch 25/100, Loss: 0.5418071533952441\n",
      "Epoch 26/100, Loss: 0.5360519226108279\n",
      "Epoch 27/100, Loss: 0.5323351323604584\n",
      "Epoch 28/100, Loss: 0.5317246168851852\n",
      "Epoch 29/100, Loss: 0.5258559393031257\n",
      "Epoch 30/100, Loss: 0.5216011319841657\n",
      "Epoch 31/100, Loss: 0.5218482741287777\n",
      "Epoch 32/100, Loss: 0.5185744294098446\n",
      "Epoch 33/100, Loss: 0.5172010617596763\n",
      "Epoch 34/100, Loss: 0.5240021305424827\n",
      "Epoch 35/100, Loss: 0.5075038522481918\n",
      "Epoch 36/100, Loss: 0.5028774269989559\n",
      "Epoch 37/100, Loss: 0.5010100496666772\n",
      "Epoch 38/100, Loss: 0.49848721495696474\n",
      "Epoch 39/100, Loss: 0.49633316695690155\n",
      "Epoch 40/100, Loss: 0.495474636554718\n",
      "Epoch 41/100, Loss: 0.4961587701525007\n",
      "Epoch 42/100, Loss: 0.4964959110532488\n",
      "Epoch 43/100, Loss: 0.4866433782236917\n",
      "Epoch 44/100, Loss: 0.4858894390719278\n",
      "Epoch 45/100, Loss: 0.48669369731630596\n",
      "Epoch 46/100, Loss: 0.48598925130707876\n",
      "Epoch 47/100, Loss: 0.4798889798777444\n",
      "Epoch 48/100, Loss: 0.4773452452250889\n",
      "Epoch 49/100, Loss: 0.4763553248984473\n",
      "Epoch 50/100, Loss: 0.4807697172675814\n",
      "Epoch 51/100, Loss: 0.47058565276009695\n",
      "Epoch 52/100, Loss: 0.4713045081921986\n",
      "Epoch 53/100, Loss: 0.46986314228602816\n",
      "Epoch 54/100, Loss: 0.4671897994620459\n",
      "Epoch 55/100, Loss: 0.46896364433424814\n",
      "Epoch 56/100, Loss: 0.4660932166235788\n",
      "Epoch 57/100, Loss: 0.46488371065684725\n",
      "Epoch 58/100, Loss: 0.4659362541777747\n",
      "Epoch 59/100, Loss: 0.46565864980220795\n",
      "Epoch 60/100, Loss: 0.46245779735701426\n",
      "Epoch 61/100, Loss: 0.46309106051921844\n",
      "Epoch 62/100, Loss: 0.46345614961215426\n",
      "Epoch 63/100, Loss: 0.458502288375582\n",
      "Epoch 64/100, Loss: 0.4654979429074696\n",
      "Epoch 65/100, Loss: 0.45917370915412903\n",
      "Epoch 66/100, Loss: 0.4597384227173669\n",
      "Epoch 67/100, Loss: 0.4580530375242233\n",
      "Epoch 68/100, Loss: 0.46149812851633343\n",
      "Epoch 69/100, Loss: 0.4620854769434248\n",
      "Epoch 70/100, Loss: 0.467226716024535\n",
      "Epoch 71/100, Loss: 0.45692149443285807\n",
      "Epoch 72/100, Loss: 0.45567608518259867\n",
      "Epoch 73/100, Loss: 0.45666291245392393\n",
      "Epoch 74/100, Loss: 0.45537662506103516\n",
      "Epoch 75/100, Loss: 0.4545872381755284\n",
      "Epoch 76/100, Loss: 0.4545541746275766\n",
      "Epoch 77/100, Loss: 0.45211169123649597\n",
      "Epoch 78/100, Loss: 0.4538203201123646\n",
      "Epoch 79/100, Loss: 0.45767004575048176\n",
      "Epoch 80/100, Loss: 0.45580378813402994\n",
      "Epoch 81/100, Loss: 0.453277981707028\n",
      "Epoch 82/100, Loss: 0.45173368070806774\n",
      "Epoch 83/100, Loss: 0.4521311862128122\n",
      "Epoch 84/100, Loss: 0.45151510408946444\n",
      "Epoch 85/100, Loss: 0.4515280936445509\n",
      "Epoch 86/100, Loss: 0.4533198390688215\n",
      "Epoch 87/100, Loss: 0.45338254954133717\n",
      "Epoch 88/100, Loss: 0.45196020177432467\n",
      "Epoch 89/100, Loss: 0.4505125305482319\n",
      "Epoch 90/100, Loss: 0.4510508158377239\n",
      "Epoch 91/100, Loss: 0.4503102536712374\n",
      "Epoch 92/100, Loss: 0.45079552062920164\n",
      "Epoch 93/100, Loss: 0.45310212884630474\n",
      "Epoch 94/100, Loss: 0.4534868597984314\n",
      "Epoch 95/100, Loss: 0.45308583974838257\n",
      "Epoch 96/100, Loss: 0.4507326143128531\n",
      "Epoch 97/100, Loss: 0.4510725076709475\n",
      "Epoch 98/100, Loss: 0.45407972378390177\n",
      "Epoch 99/100, Loss: 0.4522210316998618\n",
      "Epoch 100/100, Loss: 0.45387264660426546\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  # adjust this\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, num_epochs+1), losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 90.43062200956938%\n"
     ]
    }
   ],
   "source": [
    "PyTorchmodel.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "model_accuracy_titanic_compare[\"Pytorch Neural Network model:\"] = accuracy\n",
    "print(f'Accuracy on test set: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict time!!\n",
    "passenger_predict_tensor = torch.tensor(passenger_predict).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.605410099029541, 0.39458999037742615],\n",
       " [0.010788870975375175, 0.9892110824584961],\n",
       " [0.5447672009468079, 0.45523279905319214]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the PyTorchmodel to evaluation mode\n",
    "PyTorchmodel.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "# Convert predictions and probabilities to numpy arrays for easy printing\n",
    "predictions_np = predictions.tolist()\n",
    "probabilities_np = probabilities.tolist()\n",
    "\n",
    "# Print results\n",
    "print(predictions_np)\n",
    "probabilities_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to TensorFlow tensors\n",
    "train_features_tf = tf.convert_to_tensor(train_features.values, dtype=tf.float32)\n",
    "train_labels_tf = tf.convert_to_tensor(train_labels.values, dtype=tf.int64)\n",
    "test_features_tf = tf.convert_to_tensor(test_features.values, dtype=tf.float32)\n",
    "test_labels_tf = tf.convert_to_tensor(test_labels.values, dtype=tf.int64)\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 12  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the nn\n",
    "model_tf = models.Sequential([\n",
    "    layers.Dense(hidden_size, activation='relu', input_shape=(input_size,)),\n",
    "    layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# model_tf = models.Sequential([\n",
    "#     layers.Dense(hidden_size, activation='relu', input_shape=(input_size,), kernel_regularizer='l2'),\n",
    "#     layers.Dropout(0.3), \n",
    "#     layers.Dense(16, activation='relu', kernel_regularizer='l2'), \n",
    "#     layers.Dense(output_size, activation='softmax')\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model here\n",
    "model_tf.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# model_tf.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Assuming labels are not one-hot encoded\n",
    "#                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8594"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8025\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8081\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8025\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8002\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8126\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8036\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7991\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8013\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8081\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8081\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.8025\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8058\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8047\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8036\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8013\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7991\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7991\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7924\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7980\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8047\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8070\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8036\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8081\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7980\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8047\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8047\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8047\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.8058\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8058\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8025\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7980\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7935\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7901\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8047\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7991\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8025\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8047\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8013\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7980\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8013\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8070\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8047\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8036\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7856\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8081\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.8047\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7980\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7946\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7879\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8114\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7969\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8047\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8013\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8103\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8013\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7879\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7957\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8025\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8036\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7980\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8013\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7980\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8036\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8036\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7980\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8036\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8036\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7935\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8013\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8025\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8036\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8070\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8058\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.8013\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7946\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8036\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7991\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7980\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8036\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7957\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8103\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7957\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8002\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7991\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8036\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7890\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8058\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8058\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8002\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8103\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8025\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7946\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7890\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7946\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8081\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7980\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7980\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7946\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7935\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7845\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8013\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8002\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8126\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8013\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.8002\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.8025\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7980\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8036\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7890\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8002\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7980\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7935\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8047\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8114\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7946\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8070\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8025\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7890\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7946\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7957\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8002\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8047\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8002\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7834\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8047\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7912\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7991\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8070\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8036\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.8025\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8114\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8013\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.8047\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8047\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8058\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8047\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8070\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7980\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8081\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8081\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7935\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8013\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8002\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.8002\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7924\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8070\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.8047\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8025\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7924\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7991\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8047\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8137\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8025\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8013\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7980\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7946\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7946\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7957\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8036\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8081\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8002\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7856\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8013\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8047\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7991\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7935\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7991\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8025\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7912\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8092\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8081\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8036\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8058\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7980\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.8036\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8070\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8025\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.8036\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7991\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8002\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7946\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7991\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8058\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7991\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8081\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7924\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7924\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7935\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7957\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8036\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7991\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8047\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7969\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7969\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8036\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8070\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7991\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8002\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7901\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8036\n"
     ]
    }
   ],
   "source": [
    "#model train\n",
    "history = model_tf.fit(train_features_tf, train_labels_tf, epochs=200, batch_size=batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9593\n",
      "Accuracy on test set: 0.959330141544342\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_tf.evaluate(test_features_tf, test_labels_tf)\n",
    "model_accuracy_titanic_compare[\"Tensorflow Neural Network model:\"] = accuracy\n",
    "print(f'Accuracy on test set: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "[0 0 0]\n",
      "[[0.9158817  0.08411835]\n",
      " [0.7325382  0.2674618 ]\n",
      " [0.94435    0.05565006]]\n"
     ]
    }
   ],
   "source": [
    "passenger_predict_tf = tf.convert_to_tensor(passenger_predict, dtype=tf.float32)\n",
    "predictions_tf = model_tf.predict(passenger_predict_tf)\n",
    "predicted_classes_tf = tf.argmax(predictions_tf, axis=1).numpy()\n",
    "\n",
    "print(predicted_classes_tf)\n",
    "print(predictions_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Rregression model:': 0.9641148325358851,\n",
       " 'Decision Tree model:': 0.9617224880382775,\n",
       " 'Random Forrect Classifier model:': 0.8827751196172249,\n",
       " 'Naive Bayes Classifier model:': 0.7655502392344498,\n",
       " 'K Nearest Neighbor model:': 0.868421052631579,\n",
       " 'Support Vector Classifier model:': 0.9665071770334929,\n",
       " 'Pytorch Neural Network model:': 0.9043062200956937,\n",
       " 'Tensorflow Neural Network model:': 0.9569377899169922}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy_titanic_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
