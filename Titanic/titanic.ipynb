{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorflow](#topic-1) | [Pytorch](#topic-2) | [Visualizatons](#topic-3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data minuplations modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import viuslaization models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import normalization modules\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# import preprocessing train_test_split module\n",
    "# from sklearn.model_selection import train_test_split # Do not need this with the multiple datasets kaggle has given\n",
    "\n",
    "# import machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import NN models - Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# import NN models - Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# import accuracy_score function from sklearn.metrics to score models better\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into dataframes\n",
    "# data retrieved from kaggle competitions\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "gender_submission = pd.read_csv(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies variables for PClass to prevent bias toward one number being weighed more than another\n",
    "train = pd.concat([train, pd.get_dummies(train[\"Pclass\"], prefix=\"Pclass\")], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test[\"Pclass\"], prefix=\"Pclass\")], axis=1)\n",
    "\n",
    "# Let's make the sex cloumn into a binary column\n",
    "train[\"Sex_binary\"] = train.Sex.map({\"male\": 0, \"female\": 1})\n",
    "test[\"Sex_binary\"] = test.Sex.map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = [\"Pclass\", \"Name\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "columns_to_drop = [\"Pclass\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "train = train.drop(columns_to_drop, axis=1)\n",
    "test = test.drop(columns_to_drop, axis=1)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill in the ages with the mean of all ages.\n",
    "train[\"Age\"].fillna(\n",
    "    value=round(train[\"Age\"].mean()), inplace=True\n",
    ")  # look up .fillna function\n",
    "test[\"Age\"].fillna(value=round(test[\"Age\"].mean()), inplace=True)\n",
    "train[\"Age\"].count()  # now we have every row accounted for.\n",
    "\n",
    "# test[\"Fare\"].dropna(axis=0, how='any', inplace=True)\n",
    "test[\"Fare\"].fillna(value=round(test[\"Fare\"].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    " We were given two datasets so we will split them accordingly. WIth one dataset we would use the train_test_split function from the model selection of sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to focus on training a model on Age, Sex_binary, FirstClass, SecondClass, ThirdClass, \"SibSp\", \"Parch\", \"Fare\"\n",
    "# The goal is to predict whether or not the user survived based on this.\n",
    "train_features = train[\n",
    "    [\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]\n",
    "]\n",
    "train_labels = train[\"Survived\"]\n",
    "test_features = test[[\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]]\n",
    "test_labels = gender_submission[\"Survived\"]\n",
    "\n",
    "# initialize an accuracy test key = model , value = accuracy score\n",
    "model_accuracy_titanic_compare = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(\n",
    "    model, scaler, train_features, train_labels, test_features, test_labels\n",
    "):\n",
    "    train_features_scaled = scaler.fit_transform(train_features)\n",
    "    test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "    model.fit(train_features_scaled, train_labels)\n",
    "    y_predict = model.predict(test_features_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, y_predict)\n",
    "\n",
    "    model_key = f\"{model.__class__.__name__} - {scaler.__class__.__name__}\"\n",
    "    model_accuracy_titanic_compare[model_key] = accuracy\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Scalar Models\n",
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature data so it has mean = 0 and standard deviation = 1\n",
    "# scaler = StandardScaler()\n",
    "# train_features_Scalar = scaler.fit_transform(train_features)\n",
    "# test_features_Scalar = scaler.transform(test_features)\n",
    "\n",
    "# MinMaxScaler = MinMaxScaler()\n",
    "# train_features_MinMax = scaler.fit_transform(train_features)\n",
    "# test_features_MinMax = scaler.transform(test_features)\n",
    "\n",
    "# robust_scale = RobustScaler()\n",
    "# train_features_Robust = robust_scale.fit_transform(train_features)\n",
    "# test_features_Robust = robust_scale.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all models against 3 scalar functions\n",
    "Not the Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialze Logistic regression Models models\n",
    "model = LogisticRegression()\n",
    "model2 = LogisticRegression()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "# Initialize DecisionTreeClassifier Models\n",
    "tree_model1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "tree_model2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "tree_model3 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Initilize the RandomForest Classifiers\n",
    "RFC_model1 = RandomForestClassifier(n_estimators=80, criterion=\"gini\", max_depth=4)\n",
    "RFC_model2 = RandomForestClassifier(n_estimators=80, criterion=\"gini\", max_depth=4)\n",
    "RFC_model3 = RandomForestClassifier(n_estimators=80, criterion=\"gini\", max_depth=4)\n",
    "\n",
    "# initialize naive bayes\n",
    "nb_model1 = GaussianNB()\n",
    "nb_model2 = GaussianNB()\n",
    "nb_model3 = GaussianNB()\n",
    "\n",
    "# Initialize KNN\n",
    "knn_model1 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Initilize Support Vector Machines\n",
    "svm_svc_model1 = svm.SVC(kernel=\"poly\", C=1.5)\n",
    "svm_svc_model2 = svm.SVC(kernel=\"poly\", C=1.5)\n",
    "svm_svc_model3 = svm.SVC(kernel=\"poly\", C=1.5)\n",
    "\n",
    "# Train and evaluate models\n",
    "LR_model_acc_score_Scalar = train_and_evaluate_model(\n",
    "    model, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "LR_model_acc_score_MinMax = train_and_evaluate_model(\n",
    "    model2, min_max_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "LR_model_acc_score_Robust = train_and_evaluate_model(\n",
    "    model3, robust_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "\n",
    "DecisionTree_acc_score_Scalar = train_and_evaluate_model(\n",
    "    tree_model1, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "DecisionTree_acc_score_MinMax = train_and_evaluate_model(\n",
    "    tree_model2,\n",
    "    min_max_scaler,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_features,\n",
    "    test_labels,\n",
    ")\n",
    "DecisionTree_acc_score_Robust = train_and_evaluate_model(\n",
    "    tree_model3, robust_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "\n",
    "RandomForest_acc_score_Scalar = train_and_evaluate_model(\n",
    "    RFC_model1, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "RandomForest_acc_score_MinMax = train_and_evaluate_model(\n",
    "    RFC_model2, min_max_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "RandomForest_acc_score_Robust = train_and_evaluate_model(\n",
    "    RFC_model3, robust_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "\n",
    "NB_acc_score_Scalar = train_and_evaluate_model(\n",
    "    nb_model1, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "NB_acc_score_MinMax = train_and_evaluate_model(\n",
    "    nb_model2, min_max_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "NB_acc_score_Robust = train_and_evaluate_model(\n",
    "    nb_model3, robust_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "\n",
    "KNN_acc_score_Scalar = train_and_evaluate_model(\n",
    "    knn_model1, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "KNN_acc_score_MinMax = train_and_evaluate_model(\n",
    "    knn_model2, min_max_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "KNN_acc_score_Robust = train_and_evaluate_model(\n",
    "    knn_model3, robust_scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "\n",
    "SVC_acc_score_Scalar = train_and_evaluate_model(\n",
    "    svm_svc_model1, scaler, train_features, train_labels, test_features, test_labels\n",
    ")\n",
    "SVC_acc_score_MinMax = train_and_evaluate_model(\n",
    "    svm_svc_model2,\n",
    "    min_max_scaler,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_features,\n",
    "    test_labels,\n",
    ")\n",
    "SVC_acc_score_Robust = train_and_evaluate_model(\n",
    "    svm_svc_model3,\n",
    "    robust_scaler,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_features,\n",
    "    test_labels,\n",
    ")\n",
    "\n",
    "\n",
    "# print it all\n",
    "model_accuracy_titanic_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the contest ;)\n",
    "max_key_value_pair = max(model_accuracy_titanic_compare.items(), key=lambda x: x[1])\n",
    "print(max_key_value_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model2 = LogisticRegression()\n",
    "# model3 = LogisticRegression()\n",
    "\n",
    "# model.fit(train_features_Scalar, train_labels)\n",
    "# model2.fit(train_features_MinMax, train_labels)\n",
    "# model3.fit(train_features_Robust, train_labels)\n",
    "\n",
    "# # print(model.score(train_features, train_labels)) #I Switched to the metric module for accuracy_score\n",
    "# y_predict_Scalar = model.predict(test_features_Scalar)\n",
    "# y_predict_MinMax = model.predict(test_features_MinMax)\n",
    "# y_predict_Robust = model.predict(test_features_Robust)\n",
    "\n",
    "# LR_model_acc_score_Scalar = accuracy_score(test_labels, y_predict_Scalar)\n",
    "# LR_model_acc_score_MinMax = accuracy_score(test_labels, y_predict_MinMax)\n",
    "# LR_model_acc_score_Robust = accuracy_score(test_labels, y_predict_Robust)\n",
    "\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model Scalar:\"] = LR_model_acc_score_Scalar\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model MinMax:\"] = LR_model_acc_score_MinMax\n",
    "# model_accuracy_titanic_compare[\"Logistic Rregression model Robust:\"] = LR_model_acc_score_Robust\n",
    "# print(f\"Accuracy Scalar: {LR_model_acc_score_Scalar}\")\n",
    "# print(f\"Accuracy MinMax: {LR_model_acc_score_MinMax}\")\n",
    "# print(f\"Accuracy Robust: {LR_model_acc_score_Robust}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I remember when I did this 2 years ago, we used Jack and Rose then ourselves to make predictions on the model and we mad ethem in a np.array\n",
    "Jack = np.array([20.0, 0.0, 0.0, 0.0, 1.0, 8.0500])\n",
    "Rose = np.array([17.0, 1.0, 1.0, 0.0, 0.0, 71.2833])\n",
    "Dom = np.array([29.0, 0.0, 0.0, 1.0, 0.0, 30.0708])\n",
    "\n",
    "passenger_predict = np.array([Jack, Rose, Dom])\n",
    "\n",
    "passenger_predict = scaler.transform(passenger_predict)\n",
    "\n",
    "# prediction time! My favorite part\n",
    "# Make survival predictions!\n",
    "print(\n",
    "    model.predict(passenger_predict)\n",
    ")  # This will print a 1 or 0 for surivied or did not survive\n",
    "print(\n",
    "    model.predict_proba(passenger_predict)\n",
    ")  # this will give us how likely for each option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jack had an 88.5% of NOT surviving based on the data. \n",
    "- Rose had a 95% chance of surviving. \n",
    "- Dom would of had a 75.9% chance of NOT surviving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Decision Tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "# #does not need normalized data\n",
    "# tree_model.fit(train_features_Scalar, train_labels)\n",
    "# y_predict = tree_model.predict(test_features_Scalar)\n",
    "\n",
    "# tree_model_acc_score = accuracy_score(test_labels, y_predict)\n",
    "# model_accuracy_titanic_compare[\"Decision Tree model:\"] = tree_model_acc_score\n",
    "# print(f\"Accuracy: {tree_model_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger_predict\n",
    "print(tree_model1.predict(passenger_predict))\n",
    "print(tree_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC_model = RandomForestClassifier(n_estimators=90, criterion='gini', max_depth=5)\n",
    "\n",
    "# RFC_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_RFC = RFC_model.predict(test_features_Scalar)\n",
    "\n",
    "# #Now it should of predicted if it thinks the people in the test_features dataset survived. Lets compare that to our information of their actual survival rates\n",
    "\n",
    "# rfl_acc = accuracy_score(test_labels, y_predict_RFC)\n",
    "\n",
    "# model_accuracy_titanic_compare[\"Random Forrect Classifier model:\"] = rfl_acc\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(test_labels, y_predict_RFC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger_predict\n",
    "print(RFC_model1.predict(passenger_predict))\n",
    "print(RFC_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We should not need to do much for this one\n",
    "# nb_model = GaussianNB()\n",
    "\n",
    "# nb_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_NB = nb_model.predict(test_features_Scalar)\n",
    "\n",
    "# NB_acc_score = accuracy_score(test_labels, y_predict_NB)\n",
    "# model_accuracy_titanic_compare[\"Naive Bayes Classifier model:\"] = NB_acc_score\n",
    "# print(f\"Accuracy: {NB_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger_predict\n",
    "print(nb_model1.predict(passenger_predict))\n",
    "print(nb_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# knn_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict = knn_model.predict(test_features_Scalar)\n",
    "\n",
    "# knn_acc = accuracy_score(test_labels, y_predict)\n",
    "# model_accuracy_titanic_compare[\"K Nearest Neighbor model:\"] = knn_acc\n",
    "# knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_model1.predict(passenger_predict))\n",
    "print(knn_model1.predict_proba(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_svc_model = svm.SVC(kernel='poly', C=1.5)\n",
    "\n",
    "# svm_svc_model.fit(train_features_Scalar, train_labels)\n",
    "\n",
    "# y_predict_svm = svm_svc_model.predict(test_features_Scalar)\n",
    "\n",
    "# svm_acc = accuracy_score(test_labels, y_predict_svm)\n",
    "# model_accuracy_titanic_compare[\"Support Vector Classifier model:\"] = svm_acc\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_svc_model1.predict(passenger_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral Networks - Pytorch\n",
    "\n",
    "<a id=\"topic-2\">Pytorch</a>\n",
    "\n",
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version am I on?\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_pre_normalized = train[\n",
    "    [\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]\n",
    "]\n",
    "train_labels_pre_normalized = train[\"Survived\"]\n",
    "test_features_pre_normalized = test[\n",
    "    [\"Age\", \"Sex_binary\", \"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Fare\"]\n",
    "]\n",
    "test_labels_pre_normalized = gender_submission[\"Survived\"]\n",
    "train_features_pre_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric columns\n",
    "numeric_columns = train_features_pre_normalized.select_dtypes(\n",
    "    include=[np.number]\n",
    ").columns\n",
    "train_features_pre_normalized = train_features_pre_normalized[numeric_columns]\n",
    "test_features_pre_normalized = test_features_pre_normalized[numeric_columns]\n",
    "\n",
    "# Remove rows containing NaN values\n",
    "train_features_pre_normalized = train_features_pre_normalized.dropna()\n",
    "test_features_pre_normalized = test_features_pre_normalized.dropna()\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_features_pt = torch.tensor(train_features_pre_normalized.values).float()\n",
    "# train_labels = torch.tensor(train_labels_pre_normalized.values).float()\n",
    "test_features_pt = torch.tensor(test_features_pre_normalized.values).float()\n",
    "# test_labels = torch.tensor(test_labels_pre_normalized.values).float()\n",
    "\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "train_labels_np = train_labels.values\n",
    "test_labels_np = test_labels.values\n",
    "\n",
    "# Convert to PyTorch tensors with explicit dtype\n",
    "train_labels_pt = torch.tensor(train_labels_np, dtype=torch.long)\n",
    "test_labels_pt = torch.tensor(test_labels_np, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_features_pt, train_labels_pt)\n",
    "test_dataset = TensorDataset(test_features_pt, test_labels_pt)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TitanicNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 10  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived\n",
    "\n",
    "# Create the network\n",
    "PyTorchmodel = TitanicNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PyTorchmodel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100  # adjust this\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, num_epochs + 1), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorchmodel.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = PyTorchmodel(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "model_accuracy_titanic_compare[\"Pytorch Neural Network model:\"] = accuracy\n",
    "print(f\"Accuracy on test set: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict time!!\n",
    "\n",
    "# passenger_predict_tensor = torch.tensor(passenger_predict).float()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "#     probabilities = torch.softmax(outputs, dim=1)\n",
    "#     predictions = torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the PyTorchmodel to evaluation mode\n",
    "# PyTorchmodel.eval()\n",
    "\n",
    "# # Make predictions\n",
    "# with torch.no_grad():\n",
    "#     outputs = PyTorchmodel(passenger_predict_tensor)\n",
    "#     probabilities = torch.softmax(outputs, dim=1)\n",
    "#     predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "# # Convert predictions and probabilities to numpy arrays for easy printing\n",
    "# predictions_np = predictions.tolist()\n",
    "# probabilities_np = probabilities.tolist()\n",
    "\n",
    "# # Print results\n",
    "# print(predictions_np)\n",
    "# probabilities_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-1\">Tensorflow</a> \n",
    "\n",
    "[Back to Top](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to TensorFlow tensors\n",
    "train_features_tf = tf.convert_to_tensor(train_features.values, dtype=tf.float32)\n",
    "train_labels_tf = tf.convert_to_tensor(train_labels.values, dtype=tf.int64)\n",
    "test_features_tf = tf.convert_to_tensor(test_features.values, dtype=tf.float32)\n",
    "test_labels_tf = tf.convert_to_tensor(test_labels.values, dtype=tf.int64)\n",
    "\n",
    "# Define network dimensions\n",
    "input_size = train_features_pt.shape[1]\n",
    "hidden_size = 12  # You can adjust this\n",
    "output_size = 2  # Two classes: Survived or Not Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the nn\n",
    "model_tf = models.Sequential(\n",
    "    [\n",
    "        layers.Dense(hidden_size, activation=\"relu\", input_shape=(input_size,)),\n",
    "        layers.Dense(output_size, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model_tf = models.Sequential([\n",
    "#     layers.Dense(hidden_size, activation='relu', input_shape=(input_size,), kernel_regularizer='l2'),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(16, activation='relu', kernel_regularizer='l2'),\n",
    "#     layers.Dense(output_size, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model here\n",
    "# model_tf.compile(optimizer='adam',\n",
    "#                 loss='sparse_categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "# model_tf.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Assuming labels are not one-hot encoded\n",
    "#                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model train\n",
    "# history = model_tf.fit(train_features_tf, train_labels_tf, epochs=200, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model_tf.evaluate(test_features_tf, test_labels_tf)\n",
    "# model_accuracy_titanic_compare[\"Tensorflow Neural Network model:\"] = accuracy\n",
    "# print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger_predict_tf = tf.convert_to_tensor(passenger_predict, dtype=tf.float32)\n",
    "# predictions_tf = model_tf.predict(passenger_predict_tf)\n",
    "# predicted_classes_tf = tf.argmax(predictions_tf, axis=1).numpy()\n",
    "\n",
    "# print(predicted_classes_tf)\n",
    "# print(predictions_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_accuracy_titanic_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-3\">Visualizatons</a>\n",
    "\n",
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        k_features,\n",
    "        scoring=accuracy_score,\n",
    "        test_size=0.25,\n",
    "        random_state=1,\n",
    "    ):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_std_scalar = scaler.fit_transform(train_features)\n",
    "X_train_std_minMax = min_max_scaler.fit_transform(train_features)\n",
    "X_train_std_Robust = robust_scaler.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std_scalar, train_labels)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker=\"o\")\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = train.columns[1:]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "forest.fit(X_train_std_scalar, train_labels)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(X_train_std_scalar.shape[1]):\n",
    "    print(\n",
    "        \"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]])\n",
    "    )\n",
    "\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(X_train_std_scalar.shape[1]), importances[indices], align=\"center\")\n",
    "\n",
    "plt.xticks(range(X_train_std_scalar.shape[1]), feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train_std_scalar.shape[1]])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/04_10.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
